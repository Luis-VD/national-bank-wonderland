{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS5228 project\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_selection import RFE # for feature selection of LR\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(15, 100)\n",
    "        self.do1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(100, 150)\n",
    "        self.fc3 = nn.Linear(150, 200)\n",
    "        self.fc4 = nn.Linear(200, 100)\n",
    "        self.fc5 = nn.Linear(100, 50)\n",
    "        self.fc6 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load into dataframe\n",
    "f_data = pd.read_csv('financial_data.csv', na_values=['?']) \n",
    "revealed = pd.read_csv('revealed_businesses.csv')\n",
    "t_data = pd.read_csv('testing_data.csv', na_values=['?'])\n",
    "\n",
    "#display(f_data.head())\n",
    "#display(t_data.head())\n",
    "#display(revealed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = f_data.replace(0, np.nan) # assume 0 values also means missing\n",
    "t_data = t_data.replace(0, np.nan)\n",
    "\n",
    "f_data_merged = f_data.merge(revealed, how='outer')\n",
    "f_data_first_clean = f_data_merged.copy(deep=True)\n",
    "\n",
    "f_data_positive = f_data_merged[f_data_merged.Var66 == 0]\n",
    "f_data_negative = f_data_merged[f_data_merged.Var66 == 1]\n",
    "\n",
    "f_data_positive_clean = f_data_positive.fillna(method='ffill')\n",
    "f_data_negative_clean = f_data_negative.fillna(method='ffill')\n",
    "dfp = f_data_positive_clean.drop(columns=['Var1','Var66'])\n",
    "dfn = f_data_negative_clean.drop(columns=['Var1','Var66'])\n",
    "f_data_positive_clean_train = dfp[(np.abs(stats.zscore(dfp)) < 3).all(axis=1)]\n",
    "f_data_negative_clean_train = dfn[(np.abs(stats.zscore(dfn)) < 3).all(axis=1)]\n",
    "\n",
    "f_data_first_clean.update(f_data_positive_clean)\n",
    "f_data_first_clean.update(f_data_negative_clean)\n",
    "f_data_clean = f_data_first_clean.drop(columns=['Var66']).dropna()\n",
    "f_data_training = f_data_clean.merge(revealed)\n",
    "x_values = f_data_training.drop(columns=['Var66', 'Var1'])\n",
    "y_values = f_data_training.Var66\n",
    "x_columns = list(x_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "t_data_clean = t_data.fillna(method='bfill').drop(columns=['Var1'])\n",
    "cID = t_data['Var1'].tolist()\n",
    "t_data_columns = list(t_data_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#f_data_limited = variance_threshold_selector(f_data_no_index_no_outliers, 0.8) #x for training\n",
    "#f_data_limited_output = f_data_limited.copy(deep='true')\n",
    "#f_data_limited_output['Var66'] = training_y\n",
    "#columns_no_index_limited = list(f_data_limited_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031578</td>\n",
       "      <td>-0.219367</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>-0.065522</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.028101</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.445821</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>-0.011116</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>-0.057772</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.103971</td>\n",
       "      <td>-0.027261</td>\n",
       "      <td>-0.213907</td>\n",
       "      <td>-0.088628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114623</td>\n",
       "      <td>0.473085</td>\n",
       "      <td>-0.028456</td>\n",
       "      <td>-0.069338</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.128474</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>-0.022790</td>\n",
       "      <td>-0.428242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>-0.037085</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.057772</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.134793</td>\n",
       "      <td>-0.016953</td>\n",
       "      <td>-0.304649</td>\n",
       "      <td>0.043654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310244</td>\n",
       "      <td>0.518410</td>\n",
       "      <td>-0.142454</td>\n",
       "      <td>-0.065566</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.323582</td>\n",
       "      <td>-0.027363</td>\n",
       "      <td>-0.646302</td>\n",
       "      <td>-0.471554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104362</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.154280</td>\n",
       "      <td>-0.012374</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>-0.016767</td>\n",
       "      <td>-0.123012</td>\n",
       "      <td>-0.022165</td>\n",
       "      <td>-0.273821</td>\n",
       "      <td>-0.096631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147664</td>\n",
       "      <td>0.122847</td>\n",
       "      <td>-0.853632</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.164838</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>-0.367330</td>\n",
       "      <td>-0.093558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156144</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.034759</td>\n",
       "      <td>-0.015302</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>-0.016792</td>\n",
       "      <td>-0.088670</td>\n",
       "      <td>-0.016190</td>\n",
       "      <td>-0.307905</td>\n",
       "      <td>-0.094341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.187001</td>\n",
       "      <td>0.801967</td>\n",
       "      <td>-0.805485</td>\n",
       "      <td>-0.077174</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>-0.200662</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>0.740887</td>\n",
       "      <td>-0.742599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147965</td>\n",
       "      <td>0.014853</td>\n",
       "      <td>0.613770</td>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.198063</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>-0.110952</td>\n",
       "      <td>-0.024053</td>\n",
       "      <td>-0.256837</td>\n",
       "      <td>-0.060632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0 -0.031578 -0.219367 -0.023833 -0.065522  0.016436  0.055855 -0.028101   \n",
       "1 -0.114623  0.473085 -0.028456 -0.069338  0.016689  0.055855 -0.128474   \n",
       "2 -0.310244  0.518410 -0.142454 -0.065566  0.016455  0.055855 -0.323582   \n",
       "3 -0.147664  0.122847 -0.853632 -0.081879  0.015869  0.055855 -0.164838   \n",
       "4 -0.187001  0.801967 -0.805485 -0.077174  0.022185  0.055855 -0.200662   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.024453 -0.445821  0.158892  ...  0.135385  0.014975 -0.011116 -0.015799   \n",
       "1 -0.027264 -0.022790 -0.428242  ... -0.114428  0.014054 -0.037085 -0.015734   \n",
       "2 -0.027363 -0.646302 -0.471554  ... -0.104362  0.011261 -0.154280 -0.012374   \n",
       "3 -0.026206 -0.367330 -0.093558  ... -0.156144  0.014151 -0.034759 -0.015302   \n",
       "4 -0.027868  0.740887 -0.742599  ... -0.147965  0.014853  0.613770 -0.015536   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.057772 -0.016877 -0.103971 -0.027261 -0.213907 -0.088628  \n",
       "1 -0.057772 -0.016877 -0.134793 -0.016953 -0.304649  0.043654  \n",
       "2  0.002890 -0.016767 -0.123012 -0.022165 -0.273821 -0.096631  \n",
       "3  0.002890 -0.016792 -0.088670 -0.016190 -0.307905 -0.094341  \n",
       "4 -0.198063  0.001046 -0.110952 -0.024053 -0.256837 -0.060632  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111465</td>\n",
       "      <td>-0.059264</td>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.214773</td>\n",
       "      <td>-0.046135</td>\n",
       "      <td>0.089683</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>-0.472214</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.495542</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>-0.026152</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>-0.082314</td>\n",
       "      <td>-0.125450</td>\n",
       "      <td>-0.033877</td>\n",
       "      <td>-0.079251</td>\n",
       "      <td>0.006974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.016262</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>-0.046135</td>\n",
       "      <td>0.350676</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.308982</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086097</td>\n",
       "      <td>0.383066</td>\n",
       "      <td>0.265619</td>\n",
       "      <td>-0.026016</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>-0.072837</td>\n",
       "      <td>-0.129134</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>-0.167712</td>\n",
       "      <td>-0.004211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.054194</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>-0.059575</td>\n",
       "      <td>0.048360</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>-0.061340</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>-0.059660</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046986</td>\n",
       "      <td>1.034808</td>\n",
       "      <td>0.013562</td>\n",
       "      <td>-0.026710</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>-0.086497</td>\n",
       "      <td>-0.076747</td>\n",
       "      <td>-0.035627</td>\n",
       "      <td>-0.024564</td>\n",
       "      <td>-0.070907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.019079</td>\n",
       "      <td>-0.006677</td>\n",
       "      <td>-0.158136</td>\n",
       "      <td>-0.398692</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>-0.072916</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.867046</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330861</td>\n",
       "      <td>0.339624</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>-0.026019</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>-0.087801</td>\n",
       "      <td>-0.038655</td>\n",
       "      <td>0.051062</td>\n",
       "      <td>-0.228231</td>\n",
       "      <td>-0.084578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.040355</td>\n",
       "      <td>0.045621</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.032473</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>-0.027319</td>\n",
       "      <td>-0.028952</td>\n",
       "      <td>0.377842</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045804</td>\n",
       "      <td>-0.074061</td>\n",
       "      <td>0.018986</td>\n",
       "      <td>-0.025607</td>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>-0.079515</td>\n",
       "      <td>-0.034573</td>\n",
       "      <td>-0.061189</td>\n",
       "      <td>-0.050634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0  0.111465 -0.059264  0.082150  0.070248  0.214773 -0.046135  0.089683   \n",
       "1  0.312120  0.003651  0.016262 -0.129639  0.017582 -0.046135  0.350676   \n",
       "2 -0.040492 -0.054194  0.046872 -0.059575  0.048360  0.025709 -0.061340   \n",
       "3 -0.052139 -0.019079 -0.006677 -0.158136 -0.398692  0.025709 -0.072916   \n",
       "4 -0.006261 -0.040355  0.045621 -0.093582  0.032473  0.041712 -0.027319   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.023223 -0.472214  0.060784  ... -0.081084  0.495542  0.029833 -0.026152   \n",
       "1 -0.031098  0.308982 -0.002135  ... -0.086097  0.383066  0.265619 -0.026016   \n",
       "2 -0.025999 -0.059660  0.055714  ... -0.046986  1.034808  0.013562 -0.026710   \n",
       "3 -0.030441 -0.867046  0.020596  ... -0.330861  0.339624  0.012790 -0.026019   \n",
       "4 -0.028952  0.377842  0.041874  ... -0.045804 -0.074061  0.018986 -0.025607   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.036325 -0.082314 -0.125450 -0.033877 -0.079251  0.006974  \n",
       "1 -0.036325 -0.072837 -0.129134 -0.025464 -0.167712 -0.004211  \n",
       "2 -0.036325 -0.086497 -0.076747 -0.035627 -0.024564 -0.070907  \n",
       "3 -0.036325 -0.087801 -0.038655  0.051062 -0.228231 -0.084578  \n",
       "4 -0.015155 -0.083841 -0.079515 -0.034573 -0.061189 -0.050634  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "f_data_norm = scaler.fit_transform(x_values)\n",
    "f_data_normalized = pd.DataFrame(f_data_norm, columns=x_columns)\n",
    "\n",
    "t_data_norm = scaler.fit_transform(t_data_clean)\n",
    "t_data_normalized = pd.DataFrame(t_data_norm, columns=x_columns)\n",
    "\n",
    "display(f_data_normalized.head())\n",
    "display(t_data_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3899'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3899, 64)\n",
      "(3899,)\n",
      "(975, 64)\n",
      "(975,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(f_data_normalized.index)*0.8)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_training = f_data_normalized.iloc[:index_to_round, :]\n",
    "y_training = y_values.iloc[:index_to_round]\n",
    "\n",
    "\n",
    "x_testing = f_data_normalized.iloc[index_to_round:, :]\n",
    "y_testing = y_values.iloc[index_to_round:]\n",
    "\n",
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:\n",
    "\n",
    "Best 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "#clf.fit(x_training, y_training)\n",
    "\n",
    "rfe = RFE(clf, 15)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes\n",
    "#print(rfe.support_)\n",
    "#print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var17',\n",
       " 'Var22',\n",
       " 'Var23',\n",
       " 'Var25',\n",
       " 'Var28',\n",
       " 'Var34',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var40',\n",
       " 'Var45',\n",
       " 'Var47',\n",
       " 'Var58',\n",
       " 'Var60']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = x_columns.copy()\n",
    "GBCFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        GBCFeatures.append(feature)\n",
    "GBCFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=65, learning_rate=1, algorithm='SAMME.R', random_state=None)\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var13',\n",
       " 'Var25',\n",
       " 'Var28',\n",
       " 'Var31',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var46',\n",
       " 'Var60']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = x_columns.copy()\n",
    "ABFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        ABFeatures.append(feature)\n",
    "ABFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "rfe = RFE(clf, 20)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var5',\n",
       " 'Var10',\n",
       " 'Var11',\n",
       " 'Var12',\n",
       " 'Var13',\n",
       " 'Var17',\n",
       " 'Var23',\n",
       " 'Var25',\n",
       " 'Var27',\n",
       " 'Var29',\n",
       " 'Var35',\n",
       " 'Var36',\n",
       " 'Var37',\n",
       " 'Var39',\n",
       " 'Var47',\n",
       " 'Var49',\n",
       " 'Var51',\n",
       " 'Var55',\n",
       " 'Var62',\n",
       " 'Var64']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = x_columns.copy()\n",
    "LRFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        LRFeatures.append(feature)\n",
    "LRFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9997435239805078 Test Score:0.9702564102564103\n",
      "Test F1:0.21621621621621623\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=500, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_training[GBCFeatures], y_training)\n",
    "train_score = clf.score(x_training[GBCFeatures], y_training)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9648627853295717 Test Score:0.9692307692307692\n",
      "Test F1:0.0\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_training[GBCFeatures], y_training)\n",
    "train_score = clf.score(x_training[GBCFeatures], y_training)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9745623632385121 Test Score:0.964696223316913\n",
      "Test F1:0.18867924528301888\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=85, learning_rate=1,\n",
    "                         algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_training[ABFeatures], y_training)\n",
    "train_score = clf.score(x_training[ABFeatures], y_training)\n",
    "test_score = clf.score(x_testing[ABFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[ABFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9655361050328227 Test Score:0.9638752052545156\n",
      "Test F1:0.0\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "clf.fit(x_training[LRFeatures], y_training)\n",
    "train_score = clf.score(x_training[LRFeatures], y_training)\n",
    "test_score = clf.score(x_testing[LRFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[LRFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_10features.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized[GBCFeatures])):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=12)\n",
    "x_train_sm, y_train_sm = sm.fit_sample(x_training[GBCFeatures], y_training)\n",
    "x_train_sm_df = pd.DataFrame(data = x_train_sm, columns = GBCFeatures)\n",
    "smote_df = x_train_sm_df.copy()\n",
    "smote_df['Var66'] = y_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9974734042553192 Test Score:0.9456410256410256\n",
      "Test F1:0.34567901234567905\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='exponential', learning_rate=0.4, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_train_sm, y_train_sm)\n",
    "train_score = clf.score(x_train_sm, y_train_sm)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=15, out_features=100, bias=True)\n",
      "  (do1): Dropout(p=0.2)\n",
      "  (fc2): Linear(in_features=100, out_features=150, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=200, bias=True)\n",
      "  (fc4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc5): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc6): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6642) tensor([0.])\n",
      "[1,   500] loss: 0.10247\n",
      "tensor(1.1332) tensor([1.])\n",
      "[1,  1000] loss: 0.10557\n",
      "tensor(1.6996) tensor([1.])\n",
      "[1,  1500] loss: 0.10207\n",
      "tensor(-1.3121) tensor([0.])\n",
      "[2,   500] loss: 0.10449\n",
      "tensor(0.9810) tensor([1.])\n",
      "[2,  1000] loss: 0.10539\n",
      "tensor(-3.8386) tensor([0.])\n",
      "[2,  1500] loss: 0.10018\n",
      "tensor(0.0064) tensor([0.])\n",
      "[3,   500] loss: 0.10995\n",
      "tensor(-8.6286) tensor([0.])\n",
      "[3,  1000] loss: 0.10587\n",
      "tensor(-5.9347) tensor([0.])\n",
      "[3,  1500] loss: 0.10964\n",
      "tensor(0.9686) tensor([1.])\n",
      "[4,   500] loss: 0.09732\n",
      "tensor(-1.7024) tensor([0.])\n",
      "[4,  1000] loss: 0.09521\n",
      "tensor(0.1214) tensor([1.])\n",
      "[4,  1500] loss: 0.11120\n",
      "tensor(0.5361) tensor([1.])\n",
      "[5,   500] loss: 0.10536\n",
      "tensor(1.9390) tensor([1.])\n",
      "[5,  1000] loss: 0.09997\n",
      "tensor(-9.1979) tensor([0.])\n",
      "[5,  1500] loss: 0.10768\n",
      "tensor(-6.4498) tensor([0.])\n",
      "[6,   500] loss: 0.10053\n",
      "tensor(1.3738) tensor([1.])\n",
      "[6,  1000] loss: 0.10650\n",
      "tensor(-13.1765) tensor([0.])\n",
      "[6,  1500] loss: 0.07822\n",
      "tensor(2.7947) tensor([1.])\n",
      "[7,   500] loss: 0.10339\n",
      "tensor(-9.4219) tensor([0.])\n",
      "[7,  1000] loss: 0.11045\n",
      "tensor(1.2698) tensor([1.])\n",
      "[7,  1500] loss: 0.09746\n",
      "tensor(1.8476) tensor([0.])\n",
      "[8,   500] loss: 0.10396\n",
      "tensor(1.5841) tensor([1.])\n",
      "[8,  1000] loss: 0.09212\n",
      "tensor(-2.9477) tensor([0.])\n",
      "[8,  1500] loss: 0.10246\n",
      "tensor(1.2775) tensor([1.])\n",
      "[9,   500] loss: 0.08775\n",
      "tensor(3.3671) tensor([1.])\n",
      "[9,  1000] loss: 0.09866\n",
      "tensor(-0.3953) tensor([0.])\n",
      "[9,  1500] loss: 0.09075\n",
      "tensor(-1.8048) tensor([0.])\n",
      "[10,   500] loss: 0.09342\n",
      "tensor(1.5351) tensor([1.])\n",
      "[10,  1000] loss: 0.09765\n",
      "tensor(-38.6986) tensor([0.])\n",
      "[10,  1500] loss: 0.08966\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, 1500):\n",
    "        randn = np.random.randint(0, len(x_train_sm))\n",
    "        x_train = torch.Tensor(x_train_sm_df.iloc[randn].values).float()\n",
    "        y_train = torch.tensor([y_train_sm[randn]]).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i %500 == 499:    # print every 200 mini-batches\n",
    "            print(outputs.data[0], y_train)\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of correct: 123'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of wrong: 852'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of correct bankruptcies: 13'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of wrong bankruptcies: 6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "correct_bankruptcy = 0\n",
    "incorrect_bankruptcy = 0\n",
    "for i in range(0, len(x_testing[GBCFeatures].index)):\n",
    "    ref_x_test1 = torch.tensor(x_testing[GBCFeatures].iloc[i].values).float()\n",
    "    ref_y_test1 = torch.tensor(y_testing.iloc[i]).float()\n",
    "    outputs = net(ref_x_test1)\n",
    "    if (round(ref_y_test1.item()) == round(outputs.item())):\n",
    "        correct += 1\n",
    "    else:\n",
    "        #print(outputs.data[0], ref_y_test1.item())\n",
    "        wrong += 1\n",
    "    if (round(ref_y_test1.item()) == 1 and round(outputs.item()) == 1):\n",
    "        correct_bankruptcy +=1\n",
    "    if (round(ref_y_test1.item()) == 1 and round(outputs.item()) == 0):\n",
    "        incorrect_bankruptcy +=1\n",
    "    #print('Bankruptcy guessed correctly!')\n",
    "    #print('GroundTruth: {}'.format(ref_y_test1.item()))\n",
    "    #print('Predicted: {}'.format(outputs.item()))\n",
    "display('Number of correct: {}'.format(correct))\n",
    "display('Number of wrong: {}'.format(wrong))\n",
    "display('Number of correct bankruptcies: {}'.format(correct_bankruptcy))\n",
    "display('Number of wrong bankruptcies: {}'.format(incorrect_bankruptcy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('predictions_nn.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for i in range(0, len(t_data_normalized.index)):\n",
    "    x_test = torch.Tensor(t_data_normalized[GBCFeatures].iloc[i].values).float()\n",
    "    outputs = net(x_test)\n",
    "    f.write(str(cID[i]))\n",
    "    f.write(',')\n",
    "    f.write(str(round(outputs.item())))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_upsampled.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized[GBCFeatures])):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
