{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS5228 project\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFE # for feature selection of LR\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        #self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        #self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(20, 100)\n",
    "        self.do1 = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(100, 150)\n",
    "        self.fc3 = nn.Linear(150, 200)\n",
    "        self.fc4 = nn.Linear(200, 100)\n",
    "        self.fc5 = nn.Linear(100, 50)\n",
    "        self.fc6 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        #x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.150120</td>\n",
       "      <td>0.395670</td>\n",
       "      <td>3.63570</td>\n",
       "      <td>54.043</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>4.56831</td>\n",
       "      <td>1.01120</td>\n",
       "      <td>...</td>\n",
       "      <td>3871.001</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.98896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>5.8248</td>\n",
       "      <td>34.713</td>\n",
       "      <td>10.5150</td>\n",
       "      <td>3.4752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15092</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.726800</td>\n",
       "      <td>12.94400</td>\n",
       "      <td>233.110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063192</td>\n",
       "      <td>14.19601</td>\n",
       "      <td>0.89618</td>\n",
       "      <td>...</td>\n",
       "      <td>8751.901</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>0.93169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0492</td>\n",
       "      <td>11.1520</td>\n",
       "      <td>24.784</td>\n",
       "      <td>14.7270</td>\n",
       "      <td>4.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19821</td>\n",
       "      <td>-0.356310</td>\n",
       "      <td>0.392880</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>1.40430</td>\n",
       "      <td>-2.619</td>\n",
       "      <td>-0.085597</td>\n",
       "      <td>-0.356320</td>\n",
       "      <td>1.54531</td>\n",
       "      <td>0.92963</td>\n",
       "      <td>...</td>\n",
       "      <td>44.859</td>\n",
       "      <td>-0.172770</td>\n",
       "      <td>-0.586910</td>\n",
       "      <td>1.38330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.6112</td>\n",
       "      <td>15.7790</td>\n",
       "      <td>154.260</td>\n",
       "      <td>2.3662</td>\n",
       "      <td>2.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14171</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.708110</td>\n",
       "      <td>-0.052312</td>\n",
       "      <td>0.88978</td>\n",
       "      <td>-31.198</td>\n",
       "      <td>0.269520</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.41222</td>\n",
       "      <td>1.96540</td>\n",
       "      <td>...</td>\n",
       "      <td>-331.879</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>0.745480</td>\n",
       "      <td>17.1011</td>\n",
       "      <td>7.9482</td>\n",
       "      <td>88.147</td>\n",
       "      <td>4.1408</td>\n",
       "      <td>3.4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.346520</td>\n",
       "      <td>0.335930</td>\n",
       "      <td>2.76130</td>\n",
       "      <td>39.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>1.88591</td>\n",
       "      <td>1.29750</td>\n",
       "      <td>...</td>\n",
       "      <td>38170.001</td>\n",
       "      <td>0.212410</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>0.80158</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>9.7670</td>\n",
       "      <td>6.7570</td>\n",
       "      <td>53.651</td>\n",
       "      <td>6.8032</td>\n",
       "      <td>2.7412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2      Var3      Var4      Var5     Var6      Var7      Var8  \\\n",
       "0  18399  0.023954  0.150120  0.395670   3.63570   54.043  0.028822  0.031029   \n",
       "1  15092  0.049699  0.065808  0.726800  12.94400  233.110  0.000000  0.063192   \n",
       "2  19821 -0.356310  0.392880  0.158840   1.40430   -2.619 -0.085597 -0.356320   \n",
       "3  14171  0.001417  0.708110 -0.052312   0.88978  -31.198  0.269520  0.001407   \n",
       "4  12900  0.020041  0.346520  0.335930   2.76130   39.050  0.000000  0.020031   \n",
       "\n",
       "       Var9    Var10  ...      Var56     Var57     Var58    Var59     Var60  \\\n",
       "0   4.56831  1.01120  ...   3871.001  0.011041  0.034914  0.98896  0.000000   \n",
       "1  14.19601  0.89618  ...   8751.901  0.059565  0.053189  0.93169  0.000000   \n",
       "2   1.54531  0.92963  ...     44.859 -0.172770 -0.586910  1.38330  0.000000   \n",
       "3   0.41222  1.96540  ...   -331.879 -0.000535  0.004820  0.99930  0.745480   \n",
       "4   1.88591  1.29750  ...  38170.001  0.212410  0.030652  0.80158  0.000862   \n",
       "\n",
       "     Var61    Var62    Var63    Var64   Var65  \n",
       "0   9.5214   5.8248   34.713  10.5150  3.4752  \n",
       "1   5.0492  11.1520   24.784  14.7270  4.2204  \n",
       "2   5.6112  15.7790  154.260   2.3662  2.0738  \n",
       "3  17.1011   7.9482   88.147   4.1408  3.4021  \n",
       "4   9.7670   6.7570   53.651   6.8032  2.7412  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1  Var66\n",
       "0  18399      0\n",
       "1  19821      0\n",
       "2  17769      0\n",
       "3  19309      0\n",
       "4  20728      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load into dataframe\n",
    "f_data = pd.read_csv('financial_data.csv', na_values=['?']) \n",
    "revealed = pd.read_csv('revealed_businesses.csv')\n",
    "t_data = pd.read_csv('testing_data.csv', na_values=['?'])\n",
    "\n",
    "display(f_data.head())\n",
    "display(revealed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty_std(dataframe):\n",
    "    ones = revealed[revealed.Var66==1].Var1\n",
    "    ones_df = f_data_zeros[f_data_zeros.Var1.isin(ones)]\n",
    "    #display(ones_df)\n",
    "    zeroes = revealed[revealed.Var66==0].Var1\n",
    "    zeroes_df = f_data_zeros[f_data_zeros.Var1.isin(zeroes)]\n",
    "    #display(zeroes_df)\n",
    "    for index, row in dataframe.iterrows():\n",
    "        for column in dataframe:\n",
    "            #display((revealed[revealed.Var1==row.Var1].Var66==1).bool())\n",
    "            if ((revealed[revealed.Var1==row.Var1].Var66==1).bool):\n",
    "                col = ones_df[column]\n",
    "            else:\n",
    "                col = zeroes_df[column]\n",
    "            mean = col.mean()\n",
    "            standard_deviation = col.std()\n",
    "            if math.isnan(row[column]):\n",
    "                replacement_value = np.random.normal(mean, standard_deviation)\n",
    "                dataframe.at[index, column] = replacement_value\n",
    "                #print(\"Replaced empty value with {}\".format(replacement_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15260</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>0.13924</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>6.96220</td>\n",
       "      <td>473.710</td>\n",
       "      <td>0.614014</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>6.18171</td>\n",
       "      <td>0.79295</td>\n",
       "      <td>...</td>\n",
       "      <td>617.791</td>\n",
       "      <td>0.283210</td>\n",
       "      <td>0.125470</td>\n",
       "      <td>0.73116</td>\n",
       "      <td>-23.076565</td>\n",
       "      <td>9.7199</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>64.095</td>\n",
       "      <td>5.69470</td>\n",
       "      <td>25.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14798</td>\n",
       "      <td>0.236630</td>\n",
       "      <td>0.86496</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>1.08490</td>\n",
       "      <td>-18.866</td>\n",
       "      <td>-0.907790</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.15613</td>\n",
       "      <td>2.14410</td>\n",
       "      <td>...</td>\n",
       "      <td>156.161</td>\n",
       "      <td>0.228270</td>\n",
       "      <td>1.752300</td>\n",
       "      <td>0.79460</td>\n",
       "      <td>-12.717664</td>\n",
       "      <td>22.7391</td>\n",
       "      <td>3.2655</td>\n",
       "      <td>142.160</td>\n",
       "      <td>2.56760</td>\n",
       "      <td>22.79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16288</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.19772</td>\n",
       "      <td>0.423630</td>\n",
       "      <td>3.14500</td>\n",
       "      <td>58.018</td>\n",
       "      <td>0.018703</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>4.05761</td>\n",
       "      <td>1.50650</td>\n",
       "      <td>...</td>\n",
       "      <td>3758.001</td>\n",
       "      <td>0.546620</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.47022</td>\n",
       "      <td>40.073896</td>\n",
       "      <td>3.9728</td>\n",
       "      <td>6.4937</td>\n",
       "      <td>47.851</td>\n",
       "      <td>7.62790</td>\n",
       "      <td>3.97500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14843</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.60277</td>\n",
       "      <td>-0.193510</td>\n",
       "      <td>0.24701</td>\n",
       "      <td>-1058.700</td>\n",
       "      <td>-0.003170</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.11005</td>\n",
       "      <td>...</td>\n",
       "      <td>-22384.999</td>\n",
       "      <td>0.207050</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.79303</td>\n",
       "      <td>0.870490</td>\n",
       "      <td>2.1823</td>\n",
       "      <td>8.8410</td>\n",
       "      <td>852.310</td>\n",
       "      <td>0.42825</td>\n",
       "      <td>0.11752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16200</td>\n",
       "      <td>0.032548</td>\n",
       "      <td>0.35735</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>2.14510</td>\n",
       "      <td>18.331</td>\n",
       "      <td>-0.284547</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>1.79841</td>\n",
       "      <td>2.26320</td>\n",
       "      <td>...</td>\n",
       "      <td>3866.801</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.98583</td>\n",
       "      <td>-9.315263</td>\n",
       "      <td>7.6220</td>\n",
       "      <td>6.3231</td>\n",
       "      <td>57.632</td>\n",
       "      <td>6.33320</td>\n",
       "      <td>9.69520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2     Var3      Var4     Var5      Var6      Var7      Var8  \\\n",
       "0  15260  0.108010  0.13924  0.830200  6.96220   473.710  0.614014  0.108000   \n",
       "1  14798  0.236630  0.86496  0.070858  1.08490   -18.866 -0.907790  0.276330   \n",
       "2  16288  0.010606  0.19772  0.423630  3.14500    58.018  0.018703  0.010596   \n",
       "3  14843  0.003140  0.60277 -0.193510  0.24701 -1058.700 -0.003170  0.003130   \n",
       "4  16200  0.032548  0.35735  0.409210  2.14510    18.331 -0.284547  0.032538   \n",
       "\n",
       "      Var9    Var10  ...      Var56     Var57     Var58    Var59      Var60  \\\n",
       "0  6.18171  0.79295  ...    617.791  0.283210  0.125470  0.73116 -23.076565   \n",
       "1  0.15613  2.14410  ...    156.161  0.228270  1.752300  0.79460 -12.717664   \n",
       "2  4.05761  1.50650  ...   3758.001  0.546620  0.013208  0.47022  40.073896   \n",
       "3  0.65900  0.11005  ... -22384.999  0.207050  0.007880  0.79303   0.870490   \n",
       "4  1.79841  2.26320  ...   3866.801  0.004981  0.050632  0.98583  -9.315263   \n",
       "\n",
       "     Var61   Var62    Var63    Var64     Var65  \n",
       "0   9.7199  3.4925   64.095  5.69470  25.95000  \n",
       "1  22.7391  3.2655  142.160  2.56760  22.79400  \n",
       "2   3.9728  6.4937   47.851  7.62790   3.97500  \n",
       "3   2.1823  8.8410  852.310  0.42825   0.11752  \n",
       "4   7.6220  6.3231   57.632  6.33320   9.69520  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#clean data\n",
    "clean_and_save = False\n",
    "if clean_and_save:\n",
    "    f_data_clean = f_data.replace(0, np.nan) # assume 0 values also means missing\n",
    "    fill_empty_std(f_data_clean)\n",
    "    f_data_clean.to_pickle(\"./f_data_clean.pkl\")\n",
    "\n",
    "t_data_clean = t_data.replace(0, np.nan)\n",
    "fill_empty_std(t_data_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399.0</td>\n",
       "      <td>-0.048725</td>\n",
       "      <td>-0.085746</td>\n",
       "      <td>0.051995</td>\n",
       "      <td>-0.012682</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.036679</td>\n",
       "      <td>-0.057024</td>\n",
       "      <td>-0.019398</td>\n",
       "      <td>-0.104522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048021</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.017771</td>\n",
       "      <td>0.245694</td>\n",
       "      <td>-0.015621</td>\n",
       "      <td>-0.099369</td>\n",
       "      <td>-0.002156</td>\n",
       "      <td>0.042712</td>\n",
       "      <td>-0.079740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15092.0</td>\n",
       "      <td>-0.009047</td>\n",
       "      <td>-0.102278</td>\n",
       "      <td>0.117008</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>-0.016611</td>\n",
       "      <td>-0.007704</td>\n",
       "      <td>-0.005818</td>\n",
       "      <td>-0.118623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.011304</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>-0.018535</td>\n",
       "      <td>-0.356855</td>\n",
       "      <td>-0.015736</td>\n",
       "      <td>-0.037961</td>\n",
       "      <td>-0.002513</td>\n",
       "      <td>0.179885</td>\n",
       "      <td>-0.078069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19821.0</td>\n",
       "      <td>-0.634787</td>\n",
       "      <td>-0.038144</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>0.012159</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>-0.650996</td>\n",
       "      <td>-0.023662</td>\n",
       "      <td>-0.114522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120762</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>-0.026925</td>\n",
       "      <td>-0.012515</td>\n",
       "      <td>0.403120</td>\n",
       "      <td>-0.015722</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>-0.222671</td>\n",
       "      <td>-0.082881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14171.0</td>\n",
       "      <td>-0.083459</td>\n",
       "      <td>0.023668</td>\n",
       "      <td>-0.035960</td>\n",
       "      <td>-0.017542</td>\n",
       "      <td>0.011936</td>\n",
       "      <td>0.080314</td>\n",
       "      <td>-0.102447</td>\n",
       "      <td>-0.025261</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127924</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>-0.017634</td>\n",
       "      <td>-0.028036</td>\n",
       "      <td>-0.015427</td>\n",
       "      <td>-0.074892</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.164877</td>\n",
       "      <td>-0.079903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900.0</td>\n",
       "      <td>-0.054756</td>\n",
       "      <td>-0.047235</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>-0.014230</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.126787</td>\n",
       "      <td>-0.073888</td>\n",
       "      <td>-0.023182</td>\n",
       "      <td>-0.069423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604054</td>\n",
       "      <td>0.013837</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>-0.020269</td>\n",
       "      <td>-0.036574</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>-0.088623</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>-0.078171</td>\n",
       "      <td>-0.081385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Var1      Var2      Var3      Var4      Var5      Var6      Var7  \\\n",
       "0  18399.0 -0.048725 -0.085746  0.051995 -0.012682  0.012603  0.036679   \n",
       "1  15092.0 -0.009047 -0.102278  0.117008  0.003792  0.014003 -0.016611   \n",
       "2  19821.0 -0.634787 -0.038144  0.005497 -0.016632  0.012159  0.015936   \n",
       "3  14171.0 -0.083459  0.023668 -0.035960 -0.017542  0.011936  0.080314   \n",
       "4  12900.0 -0.054756 -0.047235  0.040266 -0.014230  0.012485  0.126787   \n",
       "\n",
       "       Var8      Var9     Var10  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.057024 -0.019398 -0.104522  ... -0.048021  0.010500  0.004109 -0.017771   \n",
       "1 -0.007704 -0.005818 -0.118623  ...  0.044772  0.011304  0.005021 -0.018535   \n",
       "2 -0.650996 -0.023662 -0.114522  ... -0.120762  0.007453 -0.026925 -0.012515   \n",
       "3 -0.102447 -0.025261  0.012458  ... -0.127924  0.010308  0.002607 -0.017634   \n",
       "4 -0.073888 -0.023182 -0.069423  ...  0.604054  0.013837  0.003896 -0.020269   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0  0.245694 -0.015621 -0.099369 -0.002156  0.042712 -0.079740  \n",
       "1 -0.356855 -0.015736 -0.037961 -0.002513  0.179885 -0.078069  \n",
       "2  0.403120 -0.015722  0.015376  0.002148 -0.222671 -0.082881  \n",
       "3 -0.028036 -0.015427 -0.074892 -0.000232 -0.164877 -0.079903  \n",
       "4 -0.036574 -0.015615 -0.088623 -0.001474 -0.078171 -0.081385  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess data\n",
    "fdatan = f_data_clean.copy(deep=True)\n",
    "normald = StandardScaler()\n",
    "fdatan_1 = normald.fit_transform(fdatan.ix[:,fdatan.columns!=\"Var1\"]) # normalize all variables except Var1\n",
    "fdatan = pd.DataFrame(np.column_stack((fdatan[\"Var1\"].values,fdatan_1)),\n",
    "                      columns = fdatan.columns).set_index(fdatan.index)\n",
    "tdatan = tdata.copy(deep=True)\n",
    "normald = StandardScaler()\n",
    "tdatan_1 = normald.fit_transform(tdatan.ix[:,tdatan.columns!=\"Var1\"]) # normalize all variables except Var1\n",
    "tdatan = pd.DataFrame(np.column_stack((tdatan[\"Var1\"].values,tdatan_1)),\n",
    "                      columns = tdatan.columns).set_index(tdatan.index)\n",
    "\n",
    "fdatan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1  Var66\n",
       "0  18399      0\n",
       "1  19821      0\n",
       "2  17769      0\n",
       "3  19309      0\n",
       "4  20728      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge dataframe\n",
    "fdatan_merged = fdatan.merge(revealed, how=\"outer\")\n",
    "fdatan_train1 = fdatan.merge(revealed) # dataframe, whose bankruptcy status is known (0 = good standing, 1 = bankrupt)\n",
    "\n",
    "display(revealed.head())\n",
    "display(len(fdatan_train1[fdatan_train1.Var66==0].index))\n",
    "len(fdatan_train1[fdatan_train1.Var66==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier here\n",
    "x1 = fdatan_train1.drop(columns=['Var1', 'Var66']) # Var 1 is company ID, Var 66 is the status\n",
    "y1 = fdatan_train1['Var66']\n",
    "t1 = tdatan.drop(columns=['Var1'])\n",
    "cID = tdata['Var1'].tolist() # use original values, since nothing is done in cID of tdata\n",
    "clas = AdaBoostClassifier() # select classifier here\n",
    "clas.fit(x1, y1)\n",
    "\n",
    "# write results to predictions.csv\n",
    "f = open('predictions.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clas.predict(t1)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3659'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var54</th>\n",
       "      <th>Var47</th>\n",
       "      <th>Var14</th>\n",
       "      <th>Var20</th>\n",
       "      <th>Var43</th>\n",
       "      <th>Var40</th>\n",
       "      <th>Var32</th>\n",
       "      <th>Var24</th>\n",
       "      <th>Var50</th>\n",
       "      <th>...</th>\n",
       "      <th>Var55</th>\n",
       "      <th>Var37</th>\n",
       "      <th>Var29</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var41</th>\n",
       "      <th>Var65</th>\n",
       "      <th>Var51</th>\n",
       "      <th>Var52</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399.0</td>\n",
       "      <td>-0.047036</td>\n",
       "      <td>-0.012879</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>0.019150</td>\n",
       "      <td>0.018861</td>\n",
       "      <td>0.019250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054590</td>\n",
       "      <td>-0.148320</td>\n",
       "      <td>-0.054708</td>\n",
       "      <td>-0.012682</td>\n",
       "      <td>-0.042860</td>\n",
       "      <td>-0.079740</td>\n",
       "      <td>-0.010554</td>\n",
       "      <td>-0.061522</td>\n",
       "      <td>-0.085746</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19821.0</td>\n",
       "      <td>-0.048708</td>\n",
       "      <td>-0.015621</td>\n",
       "      <td>-0.013029</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>-0.017326</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>-0.014543</td>\n",
       "      <td>-0.014467</td>\n",
       "      <td>-0.018604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056193</td>\n",
       "      <td>-0.406500</td>\n",
       "      <td>-0.059945</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>-0.040173</td>\n",
       "      <td>-0.082881</td>\n",
       "      <td>-0.014511</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>-0.038144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17769.0</td>\n",
       "      <td>-0.059277</td>\n",
       "      <td>-0.016913</td>\n",
       "      <td>-0.006789</td>\n",
       "      <td>0.016974</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>-0.000545</td>\n",
       "      <td>0.017811</td>\n",
       "      <td>0.017901</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066326</td>\n",
       "      <td>-0.339131</td>\n",
       "      <td>-0.069916</td>\n",
       "      <td>-0.018499</td>\n",
       "      <td>-0.060974</td>\n",
       "      <td>-0.084203</td>\n",
       "      <td>-0.016382</td>\n",
       "      <td>0.051017</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19309.0</td>\n",
       "      <td>-0.045815</td>\n",
       "      <td>-0.009409</td>\n",
       "      <td>-0.007249</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053419</td>\n",
       "      <td>0.162356</td>\n",
       "      <td>-0.056133</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>-0.077292</td>\n",
       "      <td>-0.007091</td>\n",
       "      <td>-0.074460</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20728.0</td>\n",
       "      <td>-0.051552</td>\n",
       "      <td>-0.015927</td>\n",
       "      <td>-0.006198</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.020165</td>\n",
       "      <td>0.019511</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057919</td>\n",
       "      <td>-0.120896</td>\n",
       "      <td>-0.060705</td>\n",
       "      <td>-0.016686</td>\n",
       "      <td>-0.060571</td>\n",
       "      <td>-0.080258</td>\n",
       "      <td>-0.014845</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>-0.033428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Var1     Var54     Var47     Var14     Var20     Var43     Var40  \\\n",
       "0  18399.0 -0.047036 -0.012879 -0.007115  0.018306  0.017040  0.012511   \n",
       "1  19821.0 -0.048708 -0.015621 -0.013029 -0.015309 -0.017326 -0.009299   \n",
       "2  17769.0 -0.059277 -0.016913 -0.006789  0.016974  0.016361 -0.000545   \n",
       "3  19309.0 -0.045815 -0.009409 -0.007249  0.017657  0.016336  0.011572   \n",
       "4  20728.0 -0.051552 -0.015927 -0.006198  0.019316  0.013924  0.008353   \n",
       "\n",
       "      Var32     Var24     Var50  ...     Var55     Var37     Var29      Var5  \\\n",
       "0  0.019150  0.018861  0.019250  ... -0.054590 -0.148320 -0.054708 -0.012682   \n",
       "1 -0.014543 -0.014467 -0.018604  ... -0.056193 -0.406500 -0.059945 -0.016632   \n",
       "2  0.017811  0.017901  0.016031  ... -0.066326 -0.339131 -0.069916 -0.018499   \n",
       "3  0.018497  0.018443  0.018565  ... -0.053419  0.162356 -0.056133 -0.009226   \n",
       "4  0.020165  0.019511  0.013548  ... -0.057919 -0.120896 -0.060705 -0.016686   \n",
       "\n",
       "      Var41     Var65     Var51     Var52      Var3  Var66  \n",
       "0 -0.042860 -0.079740 -0.010554 -0.061522 -0.085746      0  \n",
       "1 -0.040173 -0.082881 -0.014511 -0.013837 -0.038144      0  \n",
       "2 -0.060974 -0.084203 -0.016382  0.051017  0.026596      0  \n",
       "3  0.004689 -0.077292 -0.007091 -0.074460 -0.098662      0  \n",
       "4 -0.060571 -0.080258 -0.014845 -0.018520 -0.033428      0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_to_round = round(len(fdatan_train1.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "f_data_train_relevant = fdatan_train1[[\"Var1\",\"Var54\", \"Var47\",\"Var14\",\"Var20\",\"Var43\",\"Var40\",\"Var32\",\"Var24\",\"Var50\",\n",
    "                                      \"Var57\",\"Var6\",\"Var55\",\"Var37\",\"Var29\",\"Var5\",\"Var41\",\"Var65\",\"Var51\",\"Var52\",\n",
    "                                      \"Var3\", \"Var66\"]] \n",
    "for_training = f_data_train_relevant.iloc[:index_to_round, :]\n",
    "for_testing = f_data_train_relevant.iloc[index_to_round:, :]\n",
    "\n",
    "f_data_positives = for_training[for_training.Var66==0]\n",
    "f_data_negatives = for_training[for_training.Var66==1]\n",
    "\n",
    "x_pos = f_data_positives.drop(columns=['Var1', 'Var66'])\n",
    "y_pos = f_data_positives.Var66\n",
    "x_neg = f_data_negatives.drop(columns=['Var1', 'Var66'])\n",
    "y_neg = f_data_negatives.Var66\n",
    "x_training = for_training.drop(columns=['Var1', 'Var66'])\n",
    "y_training = for_training.Var66\n",
    "\n",
    "\n",
    "x_testing = for_testing.drop(columns=['Var1', 'Var66'])\n",
    "y_testing = for_testing.Var66\n",
    "\n",
    "display(len(x_pos.index))\n",
    "display(len(x_neg.index))\n",
    "display(f_data_train_relevant.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9650177644165072 Test Score:0.9647540983606557\n",
      "Test F1:0.0\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t1_test)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (do1): Dropout(p=0.2)\n",
      "  (fc2): Linear(in_features=100, out_features=150, bias=True)\n",
      "  (fc3): Linear(in_features=150, out_features=200, bias=True)\n",
      "  (fc4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (fc5): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (fc6): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-496-4428c95a5d84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CS5228/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CS5228/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CS5228/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/CS5228/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "for epoch in range(25):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(x_neg.index)):\n",
    "        x_train = torch.Tensor(x_neg.iloc[i].values).float()\n",
    "        y_train = torch.tensor(1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        x_train = torch.Tensor(x_pos.iloc[np.random.randint(0, len(x_pos.index))].values).float()\n",
    "        y_train = torch.tensor(0)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i == len(x_neg.index)-1:    # print every last mini-batch\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of correct: 765'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of wrong: 455'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of correct bankruptcies: 29'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Number of wrong bankruptcies: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "correct_bankruptcy = 0\n",
    "incorrect_bankruptcy = 0\n",
    "for i in range(0, len(x_testing.index)):\n",
    "    ref_x_test1 = torch.tensor(x_testing.iloc[i].values).float()\n",
    "    ref_y_test1 = torch.tensor(y_testing.iloc[i]).float()\n",
    "    outputs = net(ref_x_test1)\n",
    "    if (round(ref_y_test1.item()) == round(outputs.item())):\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "    if (round(ref_y_test1.item()) == 1 and round(outputs.item()) == 1):\n",
    "        correct_bankruptcy +=1\n",
    "    if (round(ref_y_test1.item()) == 1 and round(outputs.item()) == 0):\n",
    "        incorrect_bankruptcy +=1\n",
    "    #print('Bankruptcy guessed correctly!')\n",
    "    #print('GroundTruth: {}'.format(ref_y_test1.item()))\n",
    "    #print('Predicted: {}'.format(outputs.item()))\n",
    "display('Number of correct: {}'.format(correct))\n",
    "display('Number of wrong: {}'.format(wrong))\n",
    "display('Number of correct bankruptcies: {}'.format(correct_bankruptcy))\n",
    "display('Number of wrong bankruptcies: {}'.format(incorrect_bankruptcy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_test = t1[[\"Var54\", \"Var47\",\"Var14\",\"Var20\",\"Var43\",\"Var40\",\"Var32\",\"Var24\",\"Var50\",\"Var57\",\"Var6\",\n",
    "              \"Var55\",\"Var37\",\"Var29\",\"Var5\",\"Var41\",\"Var65\",\"Var51\",\"Var52\",\"Var3\"]]\n",
    "f = open('predictions.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for i in range(0, len(t1_test.index)):\n",
    "    x_test = torch.Tensor(t1_test.iloc[i].values).float()\n",
    "    outputs = net(x_test)\n",
    "    f.write(str(cID[i]))\n",
    "    f.write(',')\n",
    "    f.write(str(round(outputs.item())))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
