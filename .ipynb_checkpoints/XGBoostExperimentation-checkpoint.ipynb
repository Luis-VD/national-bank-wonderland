{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS5228 project\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_selection import RFE # for feature selection of LR\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load into dataframe\n",
    "f_data = pd.read_csv('financial_data.csv', na_values=['?']) \n",
    "revealed = pd.read_csv('revealed_businesses.csv')\n",
    "t_data = pd.read_csv('testing_data.csv', na_values=['?'])\n",
    "\n",
    "#display(f_data.head())\n",
    "#display(t_data.head())\n",
    "#display(revealed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "#display(f_data.isna().sum().sort_values(ascending=False))\n",
    "#f_data_2 = f_data.drop(columns=['Var38', 'Var22', 'Var61', 'Var28', 'Var61']) #Use in case of column reduction\n",
    "#columns_no_output = list(f_data_2)  #Use in case of column reduction\n",
    "#t_data_reduced = t_data[columns_no_output]\n",
    "f_data_merged = f_data.merge(revealed)\n",
    "f_data_revealed = f_data_merged[f_data_merged.Var66 != np.nan]\n",
    "\n",
    "f_data_positive = f_data_revealed[f_data_revealed.Var66 == 0]\n",
    "f_data_negative = f_data_revealed[f_data_revealed.Var66 == 1]\n",
    "\n",
    "f_data_positive_clean = f_data_positive.fillna(method='ffill')\n",
    "f_data_positive_clean = f_data_positive_clean.dropna()\n",
    "f_data_negative_clean = f_data_negative.fillna(method='ffill')\n",
    "f_data_negative_clean = f_data_negative_clean.dropna()\n",
    "\n",
    "f_data_merged_clean = f_data_positive_clean.append(f_data_negative_clean).sort_index() \n",
    "f_data_no_index = f_data_merged_clean.drop(columns=['Var1', 'Var66']) #X Training\n",
    "training_y = f_data_merged_clean.Var66 #Y training\n",
    "columns_no_index = list(f_data_no_index)\n",
    "\n",
    "f_data_positive_no_output = f_data_positive_clean.drop(columns=['Var66'])\n",
    "f_data_negative_no_output = f_data_negative_clean.drop(columns=['Var66'])\n",
    "\n",
    "t_data_clean = t_data.fillna(method='bfill').drop(columns=['Var1'])\n",
    "cID = t_data['Var1'].tolist()\n",
    "t_data_columns = list(t_data_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#f_data_limited = variance_threshold_selector(f_data_no_index_no_outliers, 0.8) #x for training\n",
    "#f_data_limited_output = f_data_limited.copy(deep='true')\n",
    "#f_data_limited_output['Var66'] = training_y\n",
    "#columns_no_index_limited = list(f_data_limited_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031578</td>\n",
       "      <td>-0.217947</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>-0.065522</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>-0.028107</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.442741</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>-0.038823</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.103804</td>\n",
       "      <td>-0.027241</td>\n",
       "      <td>-0.213160</td>\n",
       "      <td>-0.088586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114623</td>\n",
       "      <td>0.474405</td>\n",
       "      <td>-0.028456</td>\n",
       "      <td>-0.069338</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.128480</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>-0.020177</td>\n",
       "      <td>-0.428242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.134625</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>-0.303888</td>\n",
       "      <td>0.043696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310244</td>\n",
       "      <td>0.519723</td>\n",
       "      <td>-0.142454</td>\n",
       "      <td>-0.065566</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.323589</td>\n",
       "      <td>-0.027363</td>\n",
       "      <td>-0.643001</td>\n",
       "      <td>-0.471554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104362</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.154133</td>\n",
       "      <td>-0.012374</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>-0.016767</td>\n",
       "      <td>-0.122845</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>-0.273064</td>\n",
       "      <td>-0.096589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147664</td>\n",
       "      <td>0.124218</td>\n",
       "      <td>-0.853632</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.164845</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>-0.364337</td>\n",
       "      <td>-0.093558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156144</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>-0.015302</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016792</td>\n",
       "      <td>-0.088503</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>-0.307144</td>\n",
       "      <td>-0.094299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.187001</td>\n",
       "      <td>0.803238</td>\n",
       "      <td>-0.805485</td>\n",
       "      <td>-0.077174</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.200669</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>0.742657</td>\n",
       "      <td>-0.742599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147965</td>\n",
       "      <td>0.014853</td>\n",
       "      <td>0.613947</td>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.194292</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>-0.110785</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.256083</td>\n",
       "      <td>-0.060590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0 -0.031578 -0.217947 -0.023833 -0.065522  0.016436  0.043052 -0.028107   \n",
       "1 -0.114623  0.474405 -0.028456 -0.069338  0.016689  0.017261 -0.128480   \n",
       "2 -0.310244  0.519723 -0.142454 -0.065566  0.016455  0.017261 -0.323589   \n",
       "3 -0.147664  0.124218 -0.853632 -0.081879  0.015869  0.017261 -0.164845   \n",
       "4 -0.187001  0.803238 -0.805485 -0.077174  0.022185  0.017261 -0.200669   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.024453 -0.442741  0.158892  ...  0.135385  0.014975 -0.010964 -0.015799   \n",
       "1 -0.027264 -0.020177 -0.428242  ... -0.114428  0.014054 -0.036933 -0.015734   \n",
       "2 -0.027363 -0.643001 -0.471554  ... -0.104362  0.011261 -0.154133 -0.012374   \n",
       "3 -0.026206 -0.364337 -0.093558  ... -0.156144  0.014151 -0.034607 -0.015302   \n",
       "4 -0.027868  0.742657 -0.742599  ... -0.147965  0.014853  0.613947 -0.015536   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.038823 -0.016877 -0.103804 -0.027241 -0.213160 -0.088586  \n",
       "1 -0.044719 -0.016877 -0.134625 -0.016933 -0.303888  0.043696  \n",
       "2  0.028404 -0.016767 -0.122845 -0.022144 -0.273064 -0.096589  \n",
       "3 -0.044719 -0.016792 -0.088503 -0.016169 -0.307144 -0.094299  \n",
       "4 -0.194292  0.001046 -0.110785 -0.024033 -0.256083 -0.060590  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111465</td>\n",
       "      <td>-0.059198</td>\n",
       "      <td>0.082161</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>-0.466343</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.495542</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.082314</td>\n",
       "      <td>-0.123844</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.078187</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>-0.046425</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086097</td>\n",
       "      <td>0.383066</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.072837</td>\n",
       "      <td>-0.127529</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>-0.166636</td>\n",
       "      <td>-0.003845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.054128</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.059575</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>-0.054489</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046986</td>\n",
       "      <td>1.034808</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.086497</td>\n",
       "      <td>-0.075128</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.019013</td>\n",
       "      <td>-0.006665</td>\n",
       "      <td>-0.158136</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.860506</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330861</td>\n",
       "      <td>0.339624</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>-0.087801</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.227147</td>\n",
       "      <td>-0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.028952</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045804</td>\n",
       "      <td>-0.074061</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>-0.077897</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.060127</td>\n",
       "      <td>-0.050267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0  0.111465 -0.059198  0.082161  0.070248  0.214767  0.025733  0.090308   \n",
       "1  0.312120  0.003717  0.016274 -0.129639  0.017576 -0.046425  0.351322   \n",
       "2 -0.040492 -0.054128  0.046884 -0.059575  0.048355  0.025733 -0.060728   \n",
       "3 -0.052139 -0.019013 -0.006665 -0.158136 -0.398698  0.025481 -0.072305   \n",
       "4 -0.006261 -0.040289  0.045632 -0.093582  0.032467  0.025733 -0.026704   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.023223 -0.466343  0.060784  ... -0.081084  0.495542  0.030066 -0.026149   \n",
       "1 -0.031098  0.313527 -0.002135  ... -0.086097  0.383066  0.265854 -0.026013   \n",
       "2 -0.025999 -0.054489  0.055714  ... -0.046986  1.034808  0.013795 -0.026707   \n",
       "3 -0.030441 -0.860506  0.020596  ... -0.330861  0.339624  0.013022 -0.026017   \n",
       "4 -0.028952  0.382270  0.041874  ... -0.045804 -0.074061  0.019219 -0.025604   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.058331 -0.082314 -0.123844 -0.033871 -0.078187  0.007340  \n",
       "1 -0.058331 -0.072837 -0.127529 -0.025458 -0.166636 -0.003845  \n",
       "2 -0.058331 -0.086497 -0.075128 -0.035621 -0.023507 -0.070540  \n",
       "3  0.017325 -0.087801 -0.037025  0.051068 -0.227147 -0.084211  \n",
       "4 -0.058331 -0.083841 -0.077897 -0.034567 -0.060127 -0.050267  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "f_data_norm = scaler.fit_transform(f_data_no_index)\n",
    "f_data_normalized = pd.DataFrame(f_data_norm, columns=columns_no_index)\n",
    "\n",
    "t_data_norm = scaler.fit_transform(t_data_clean)\n",
    "t_data_normalized = pd.DataFrame(t_data_norm, columns=t_data_columns)\n",
    "\n",
    "display(f_data_normalized.head())\n",
    "display(t_data_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3656'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 64)\n",
      "(3656,)\n",
      "(1218, 64)\n",
      "(1218,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(f_data_normalized.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_training = f_data_normalized.iloc[:index_to_round, :]\n",
    "y_training = training_y.iloc[:index_to_round]\n",
    "\n",
    "\n",
    "x_testing = f_data_normalized.iloc[index_to_round:, :]\n",
    "y_testing = training_y.iloc[index_to_round:]\n",
    "\n",
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b\"Invalid Parameter format for silent expect boolean but value='None'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bdf66155a142>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mreg_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_pos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     missing=None)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_testing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_testing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    711\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1110\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b\"Invalid Parameter format for silent expect boolean but value='None'\""
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None,\n",
    "                    objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1,\n",
    "                    max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1,\n",
    "                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None,\n",
    "                    missing=None)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:\n",
    "\n",
    "Best 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "#clf.fit(x_training, y_training)\n",
    "\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes\n",
    "#print(rfe.support_)\n",
    "#print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var16',\n",
       " 'Var22',\n",
       " 'Var23',\n",
       " 'Var25',\n",
       " 'Var28',\n",
       " 'Var29',\n",
       " 'Var31',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var47']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "GBCFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        GBCFeatures.append(feature)\n",
    "GBCFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=65, learning_rate=1, algorithm='SAMME.R', random_state=None)\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var14',\n",
       " 'Var22',\n",
       " 'Var28',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var40',\n",
       " 'Var46',\n",
       " 'Var47']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "ABFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        ABFeatures.append(feature)\n",
    "ABFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var13',\n",
       " 'Var23',\n",
       " 'Var25',\n",
       " 'Var29',\n",
       " 'Var35',\n",
       " 'Var36',\n",
       " 'Var47',\n",
       " 'Var49',\n",
       " 'Var51',\n",
       " 'Var64']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "LRFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        LRFeatures.append(feature)\n",
    "LRFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9781181619256017 Test Score:0.951559934318555\n",
      "Test F1:0.11940298507462685\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.6, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_training[GBCFeatures], y_training)\n",
    "train_score = clf.score(x_training[GBCFeatures], y_training)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9674507658643327 Test Score:0.9614121510673235\n",
      "Test F1:0.0\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_training[GBCFeatures], y_training)\n",
    "train_score = clf.score(x_training[GBCFeatures], y_training)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9745623632385121 Test Score:0.964696223316913\n",
      "Test F1:0.18867924528301888\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=85, learning_rate=1,\n",
    "                         algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_training[ABFeatures], y_training)\n",
    "train_score = clf.score(x_training[ABFeatures], y_training)\n",
    "test_score = clf.score(x_testing[ABFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[ABFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9655361050328227 Test Score:0.9638752052545156\n",
      "Test F1:0.0\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                         class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', \n",
    "                         verbose=0, warm_start=False, n_jobs=-1)\n",
    "clf.fit(x_training[LRFeatures], y_training)\n",
    "train_score = clf.score(x_training[LRFeatures], y_training)\n",
    "test_score = clf.score(x_testing[LRFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[LRFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_10features.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized[GBCFeatures])):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=12)\n",
    "x_train_sm, y_train_sm = sm.fit_sample(x_training[GBCFeatures], y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9808781869688386 Test Score:0.9252873563218391\n",
      "Test F1:0.3053435114503817\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=500, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_train_sm, y_train_sm)\n",
    "train_score = clf.score(x_train_sm, y_train_sm)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_upsampled.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized[GBCFeatures])):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "#clf.fit(x_training, y_training)\n",
    "\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_train_sm, y_train_sm)\n",
    "# summarize the selection of the attributes\n",
    "#print(rfe.support_)\n",
    "#print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var14',\n",
       " 'Var25',\n",
       " 'Var27',\n",
       " 'Var28',\n",
       " 'Var35',\n",
       " 'Var42',\n",
       " 'Var63',\n",
       " 'Var65']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "GBCFeatures = []\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        GBCFeatures.append(feature)\n",
    "GBCFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9854107648725212 Test Score:0.9261083743842364\n",
      "Test F1:0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=500, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_train_sm, y_train_sm)\n",
    "train_score = clf.score(x_train_sm, y_train_sm)\n",
    "test_score = clf.score(x_testing[GBCFeatures], y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing[GBCFeatures]))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_upsampled.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized[GBCFeatures])):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
