{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS5228 project\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_selection import RFE # for feature selection of LR\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.150120</td>\n",
       "      <td>0.395670</td>\n",
       "      <td>3.63570</td>\n",
       "      <td>54.043</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>4.56831</td>\n",
       "      <td>1.01120</td>\n",
       "      <td>...</td>\n",
       "      <td>3871.001</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.98896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>5.8248</td>\n",
       "      <td>34.713</td>\n",
       "      <td>10.5150</td>\n",
       "      <td>3.4752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15092</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.726800</td>\n",
       "      <td>12.94400</td>\n",
       "      <td>233.110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063192</td>\n",
       "      <td>14.19601</td>\n",
       "      <td>0.89618</td>\n",
       "      <td>...</td>\n",
       "      <td>8751.901</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>0.93169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0492</td>\n",
       "      <td>11.1520</td>\n",
       "      <td>24.784</td>\n",
       "      <td>14.7270</td>\n",
       "      <td>4.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19821</td>\n",
       "      <td>-0.356310</td>\n",
       "      <td>0.392880</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>1.40430</td>\n",
       "      <td>-2.619</td>\n",
       "      <td>-0.085597</td>\n",
       "      <td>-0.356320</td>\n",
       "      <td>1.54531</td>\n",
       "      <td>0.92963</td>\n",
       "      <td>...</td>\n",
       "      <td>44.859</td>\n",
       "      <td>-0.172770</td>\n",
       "      <td>-0.586910</td>\n",
       "      <td>1.38330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.6112</td>\n",
       "      <td>15.7790</td>\n",
       "      <td>154.260</td>\n",
       "      <td>2.3662</td>\n",
       "      <td>2.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14171</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.708110</td>\n",
       "      <td>-0.052312</td>\n",
       "      <td>0.88978</td>\n",
       "      <td>-31.198</td>\n",
       "      <td>0.269520</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.41222</td>\n",
       "      <td>1.96540</td>\n",
       "      <td>...</td>\n",
       "      <td>-331.879</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>0.745480</td>\n",
       "      <td>17.1011</td>\n",
       "      <td>7.9482</td>\n",
       "      <td>88.147</td>\n",
       "      <td>4.1408</td>\n",
       "      <td>3.4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.346520</td>\n",
       "      <td>0.335930</td>\n",
       "      <td>2.76130</td>\n",
       "      <td>39.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>1.88591</td>\n",
       "      <td>1.29750</td>\n",
       "      <td>...</td>\n",
       "      <td>38170.001</td>\n",
       "      <td>0.212410</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>0.80158</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>9.7670</td>\n",
       "      <td>6.7570</td>\n",
       "      <td>53.651</td>\n",
       "      <td>6.8032</td>\n",
       "      <td>2.7412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2      Var3      Var4      Var5     Var6      Var7      Var8  \\\n",
       "0  18399  0.023954  0.150120  0.395670   3.63570   54.043  0.028822  0.031029   \n",
       "1  15092  0.049699  0.065808  0.726800  12.94400  233.110  0.000000  0.063192   \n",
       "2  19821 -0.356310  0.392880  0.158840   1.40430   -2.619 -0.085597 -0.356320   \n",
       "3  14171  0.001417  0.708110 -0.052312   0.88978  -31.198  0.269520  0.001407   \n",
       "4  12900  0.020041  0.346520  0.335930   2.76130   39.050  0.000000  0.020031   \n",
       "\n",
       "       Var9    Var10  ...      Var56     Var57     Var58    Var59     Var60  \\\n",
       "0   4.56831  1.01120  ...   3871.001  0.011041  0.034914  0.98896  0.000000   \n",
       "1  14.19601  0.89618  ...   8751.901  0.059565  0.053189  0.93169  0.000000   \n",
       "2   1.54531  0.92963  ...     44.859 -0.172770 -0.586910  1.38330  0.000000   \n",
       "3   0.41222  1.96540  ...   -331.879 -0.000535  0.004820  0.99930  0.745480   \n",
       "4   1.88591  1.29750  ...  38170.001  0.212410  0.030652  0.80158  0.000862   \n",
       "\n",
       "     Var61    Var62    Var63    Var64   Var65  \n",
       "0   9.5214   5.8248   34.713  10.5150  3.4752  \n",
       "1   5.0492  11.1520   24.784  14.7270  4.2204  \n",
       "2   5.6112  15.7790  154.260   2.3662  2.0738  \n",
       "3  17.1011   7.9482   88.147   4.1408  3.4021  \n",
       "4   9.7670   6.7570   53.651   6.8032  2.7412  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15260</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>0.13924</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>6.96220</td>\n",
       "      <td>473.710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>6.18171</td>\n",
       "      <td>0.79295</td>\n",
       "      <td>...</td>\n",
       "      <td>617.791</td>\n",
       "      <td>0.283210</td>\n",
       "      <td>0.125470</td>\n",
       "      <td>0.73116</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.7199</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>64.095</td>\n",
       "      <td>5.69470</td>\n",
       "      <td>25.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14798</td>\n",
       "      <td>0.236630</td>\n",
       "      <td>0.86496</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>1.08490</td>\n",
       "      <td>-18.866</td>\n",
       "      <td>-0.90779</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.15613</td>\n",
       "      <td>2.14410</td>\n",
       "      <td>...</td>\n",
       "      <td>156.161</td>\n",
       "      <td>0.228270</td>\n",
       "      <td>1.752300</td>\n",
       "      <td>0.79460</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>22.7391</td>\n",
       "      <td>3.2655</td>\n",
       "      <td>142.160</td>\n",
       "      <td>2.56760</td>\n",
       "      <td>22.79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16288</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.19772</td>\n",
       "      <td>0.423630</td>\n",
       "      <td>3.14500</td>\n",
       "      <td>58.018</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>4.05761</td>\n",
       "      <td>1.50650</td>\n",
       "      <td>...</td>\n",
       "      <td>3758.001</td>\n",
       "      <td>0.546620</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.47022</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.9728</td>\n",
       "      <td>6.4937</td>\n",
       "      <td>47.851</td>\n",
       "      <td>7.62790</td>\n",
       "      <td>3.97500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14843</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.60277</td>\n",
       "      <td>-0.193510</td>\n",
       "      <td>0.24701</td>\n",
       "      <td>-1058.700</td>\n",
       "      <td>-0.00317</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.11005</td>\n",
       "      <td>...</td>\n",
       "      <td>-22384.999</td>\n",
       "      <td>0.207050</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.79303</td>\n",
       "      <td>0.87049</td>\n",
       "      <td>2.1823</td>\n",
       "      <td>8.8410</td>\n",
       "      <td>852.310</td>\n",
       "      <td>0.42825</td>\n",
       "      <td>0.11752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16200</td>\n",
       "      <td>0.032548</td>\n",
       "      <td>0.35735</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>2.14510</td>\n",
       "      <td>18.331</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>1.79841</td>\n",
       "      <td>2.26320</td>\n",
       "      <td>...</td>\n",
       "      <td>3866.801</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.98583</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.6220</td>\n",
       "      <td>6.3231</td>\n",
       "      <td>57.632</td>\n",
       "      <td>6.33320</td>\n",
       "      <td>9.69520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2     Var3      Var4     Var5      Var6     Var7      Var8  \\\n",
       "0  15260  0.108010  0.13924  0.830200  6.96220   473.710  0.00000  0.108000   \n",
       "1  14798  0.236630  0.86496  0.070858  1.08490   -18.866 -0.90779  0.276330   \n",
       "2  16288  0.010606  0.19772  0.423630  3.14500    58.018  0.00000  0.010596   \n",
       "3  14843  0.003140  0.60277 -0.193510  0.24701 -1058.700 -0.00317  0.003130   \n",
       "4  16200  0.032548  0.35735  0.409210  2.14510    18.331  0.00000  0.032538   \n",
       "\n",
       "      Var9    Var10  ...      Var56     Var57     Var58    Var59    Var60  \\\n",
       "0  6.18171  0.79295  ...    617.791  0.283210  0.125470  0.73116  0.00000   \n",
       "1  0.15613  2.14410  ...    156.161  0.228270  1.752300  0.79460  0.00000   \n",
       "2  4.05761  1.50650  ...   3758.001  0.546620  0.013208  0.47022  0.00000   \n",
       "3  0.65900  0.11005  ... -22384.999  0.207050  0.007880  0.79303  0.87049   \n",
       "4  1.79841  2.26320  ...   3866.801  0.004981  0.050632  0.98583  0.00000   \n",
       "\n",
       "     Var61   Var62    Var63    Var64     Var65  \n",
       "0   9.7199  3.4925   64.095  5.69470  25.95000  \n",
       "1  22.7391  3.2655  142.160  2.56760  22.79400  \n",
       "2   3.9728  6.4937   47.851  7.62790   3.97500  \n",
       "3   2.1823  8.8410  852.310  0.42825   0.11752  \n",
       "4   7.6220  6.3231   57.632  6.33320   9.69520  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1  Var66\n",
       "0  18399      0\n",
       "1  19821      0\n",
       "2  17769      0\n",
       "3  19309      0\n",
       "4  20728      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load into dataframe\n",
    "f_data = pd.read_csv('financial_data.csv', na_values=['?']) \n",
    "revealed = pd.read_csv('revealed_businesses.csv')\n",
    "t_data = pd.read_csv('testing_data.csv', na_values=['?'])\n",
    "\n",
    "display(f_data.head())\n",
    "display(t_data.head())\n",
    "display(revealed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "#display(f_data.isna().sum().sort_values(ascending=False))\n",
    "#f_data_2 = f_data.drop(columns=['Var38', 'Var22', 'Var61', 'Var28', 'Var61']) #Use in case of column reduction\n",
    "#columns_no_output = list(f_data_2)  #Use in case of column reduction\n",
    "#t_data_reduced = t_data[columns_no_output]\n",
    "f_data_merged = f_data.merge(revealed)\n",
    "f_data_revealed = f_data_merged[f_data_merged.Var66 != np.nan]\n",
    "\n",
    "f_data_positive = f_data_revealed[f_data_revealed.Var66 == 0]\n",
    "f_data_negative = f_data_revealed[f_data_revealed.Var66 == 1]\n",
    "\n",
    "f_data_positive_clean = f_data_positive.fillna(method='ffill')\n",
    "f_data_positive_clean = f_data_positive_clean.dropna()\n",
    "f_data_negative_clean = f_data_negative.fillna(method='ffill')\n",
    "f_data_negative_clean = f_data_negative_clean.dropna()\n",
    "\n",
    "f_data_merged_clean = f_data_positive_clean.append(f_data_negative_clean).sort_index() \n",
    "f_data_no_index = f_data_merged_clean.drop(columns=['Var1', 'Var66']) #X Training\n",
    "training_y = f_data_merged_clean.Var66 #Y training\n",
    "columns_no_index = list(f_data_no_index)\n",
    "\n",
    "f_data_positive_no_output = f_data_positive_clean.drop(columns=['Var66'])\n",
    "f_data_negative_no_output = f_data_negative_clean.drop(columns=['Var66'])\n",
    "\n",
    "t_data_clean = t_data.fillna(method='bfill').drop(columns=['Var1'])\n",
    "cID = t_data['Var1'].tolist()\n",
    "t_data_columns = list(t_data_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#f_data_limited = variance_threshold_selector(f_data_no_index_no_outliers, 0.8) #x for training\n",
    "#f_data_limited_output = f_data_limited.copy(deep='true')\n",
    "#f_data_limited_output['Var66'] = training_y\n",
    "#columns_no_index_limited = list(f_data_limited_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(f_data.isna().sum())\n",
    "#display(f_data_merged_clean.isnull().sum())\n",
    "#display(f_data_revealed.isnull().sum())\n",
    "#display(f_data_merged_clean.Var66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031578</td>\n",
       "      <td>-0.217947</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>-0.065522</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>-0.028107</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.442741</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>-0.038823</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.103804</td>\n",
       "      <td>-0.027241</td>\n",
       "      <td>-0.213160</td>\n",
       "      <td>-0.088586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114623</td>\n",
       "      <td>0.474405</td>\n",
       "      <td>-0.028456</td>\n",
       "      <td>-0.069338</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.128480</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>-0.020177</td>\n",
       "      <td>-0.428242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.134625</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>-0.303888</td>\n",
       "      <td>0.043696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310244</td>\n",
       "      <td>0.519723</td>\n",
       "      <td>-0.142454</td>\n",
       "      <td>-0.065566</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.323589</td>\n",
       "      <td>-0.027363</td>\n",
       "      <td>-0.643001</td>\n",
       "      <td>-0.471554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104362</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.154133</td>\n",
       "      <td>-0.012374</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>-0.016767</td>\n",
       "      <td>-0.122845</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>-0.273064</td>\n",
       "      <td>-0.096589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147664</td>\n",
       "      <td>0.124218</td>\n",
       "      <td>-0.853632</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.164845</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>-0.364337</td>\n",
       "      <td>-0.093558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156144</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>-0.015302</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016792</td>\n",
       "      <td>-0.088503</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>-0.307144</td>\n",
       "      <td>-0.094299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.187001</td>\n",
       "      <td>0.803238</td>\n",
       "      <td>-0.805485</td>\n",
       "      <td>-0.077174</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.200669</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>0.742657</td>\n",
       "      <td>-0.742599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147965</td>\n",
       "      <td>0.014853</td>\n",
       "      <td>0.613947</td>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.194292</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>-0.110785</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.256083</td>\n",
       "      <td>-0.060590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0 -0.031578 -0.217947 -0.023833 -0.065522  0.016436  0.043052 -0.028107   \n",
       "1 -0.114623  0.474405 -0.028456 -0.069338  0.016689  0.017261 -0.128480   \n",
       "2 -0.310244  0.519723 -0.142454 -0.065566  0.016455  0.017261 -0.323589   \n",
       "3 -0.147664  0.124218 -0.853632 -0.081879  0.015869  0.017261 -0.164845   \n",
       "4 -0.187001  0.803238 -0.805485 -0.077174  0.022185  0.017261 -0.200669   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.024453 -0.442741  0.158892  ...  0.135385  0.014975 -0.010964 -0.015799   \n",
       "1 -0.027264 -0.020177 -0.428242  ... -0.114428  0.014054 -0.036933 -0.015734   \n",
       "2 -0.027363 -0.643001 -0.471554  ... -0.104362  0.011261 -0.154133 -0.012374   \n",
       "3 -0.026206 -0.364337 -0.093558  ... -0.156144  0.014151 -0.034607 -0.015302   \n",
       "4 -0.027868  0.742657 -0.742599  ... -0.147965  0.014853  0.613947 -0.015536   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.038823 -0.016877 -0.103804 -0.027241 -0.213160 -0.088586  \n",
       "1 -0.044719 -0.016877 -0.134625 -0.016933 -0.303888  0.043696  \n",
       "2  0.028404 -0.016767 -0.122845 -0.022144 -0.273064 -0.096589  \n",
       "3 -0.044719 -0.016792 -0.088503 -0.016169 -0.307144 -0.094299  \n",
       "4 -0.194292  0.001046 -0.110785 -0.024033 -0.256083 -0.060590  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111465</td>\n",
       "      <td>-0.059198</td>\n",
       "      <td>0.082161</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>-0.466343</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.495542</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.082314</td>\n",
       "      <td>-0.123844</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.078187</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>-0.046425</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086097</td>\n",
       "      <td>0.383066</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.072837</td>\n",
       "      <td>-0.127529</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>-0.166636</td>\n",
       "      <td>-0.003845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.054128</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.059575</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>-0.054489</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046986</td>\n",
       "      <td>1.034808</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.086497</td>\n",
       "      <td>-0.075128</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.019013</td>\n",
       "      <td>-0.006665</td>\n",
       "      <td>-0.158136</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.860506</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330861</td>\n",
       "      <td>0.339624</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>-0.087801</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.227147</td>\n",
       "      <td>-0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.028952</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045804</td>\n",
       "      <td>-0.074061</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>-0.077897</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.060127</td>\n",
       "      <td>-0.050267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0  0.111465 -0.059198  0.082161  0.070248  0.214767  0.025733  0.090308   \n",
       "1  0.312120  0.003717  0.016274 -0.129639  0.017576 -0.046425  0.351322   \n",
       "2 -0.040492 -0.054128  0.046884 -0.059575  0.048355  0.025733 -0.060728   \n",
       "3 -0.052139 -0.019013 -0.006665 -0.158136 -0.398698  0.025481 -0.072305   \n",
       "4 -0.006261 -0.040289  0.045632 -0.093582  0.032467  0.025733 -0.026704   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.023223 -0.466343  0.060784  ... -0.081084  0.495542  0.030066 -0.026149   \n",
       "1 -0.031098  0.313527 -0.002135  ... -0.086097  0.383066  0.265854 -0.026013   \n",
       "2 -0.025999 -0.054489  0.055714  ... -0.046986  1.034808  0.013795 -0.026707   \n",
       "3 -0.030441 -0.860506  0.020596  ... -0.330861  0.339624  0.013022 -0.026017   \n",
       "4 -0.028952  0.382270  0.041874  ... -0.045804 -0.074061  0.019219 -0.025604   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.058331 -0.082314 -0.123844 -0.033871 -0.078187  0.007340  \n",
       "1 -0.058331 -0.072837 -0.127529 -0.025458 -0.166636 -0.003845  \n",
       "2 -0.058331 -0.086497 -0.075128 -0.035621 -0.023507 -0.070540  \n",
       "3  0.017325 -0.087801 -0.037025  0.051068 -0.227147 -0.084211  \n",
       "4 -0.058331 -0.083841 -0.077897 -0.034567 -0.060127 -0.050267  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "f_data_norm = scaler.fit_transform(f_data_no_index)\n",
    "f_data_normalized = pd.DataFrame(f_data_norm, columns=columns_no_index)\n",
    "\n",
    "t_data_norm = scaler.fit_transform(t_data_clean)\n",
    "t_data_normalized = pd.DataFrame(t_data_norm, columns=t_data_columns)\n",
    "\n",
    "display(f_data_normalized.head())\n",
    "display(t_data_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3656'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 64)\n",
      "(3656,)\n",
      "(1218, 64)\n",
      "(1218,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(f_data_normalized.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_training = f_data_normalized.iloc[:index_to_round, :]\n",
    "y_training = training_y.iloc[:index_to_round]\n",
    "\n",
    "\n",
    "x_testing = f_data_normalized.iloc[index_to_round:, :]\n",
    "y_testing = training_y.iloc[index_to_round:]\n",
    "\n",
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9896061269146609 Test Score:0.9622331691297209\n",
      "Test F1:0.2068965517241379\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9669037199124726 Test Score:0.9655172413793104\n",
      "Test F1:0.04545454545454545\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                           p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9729212253829321 Test Score:0.9655172413793104\n",
      "Test F1:0.22222222222222218\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=65, learning_rate=1, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_basic.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-sampling:\n",
    "x_full = f_data_normalized.copy()\n",
    "x_maj = x_full[x_full.Var66==0]\n",
    "x_min = x_full[x_full.Var66==1]\n",
    "x_maj_rus = resample(x_maj,replace=False,n_samples=len(x_min),random_state=44)\n",
    "x_rus = pd.concat([x_maj_rus, x_min])\n",
    "x_train_rus = x_rus.drop(columns=['Var66'])\n",
    "y_train_rus = x_rus.Var66\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train_sm, y_train_sm = sm.fit_sample(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.958128078817734\n",
      "Test F1:0.33766233766233766\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.3, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_train_sm, y_train_sm)\n",
    "train_score = clf.score(x_train_sm, y_train_sm)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_upsampled.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means F1: -0.0003935127911477825\n"
     ]
    }
   ],
   "source": [
    "#Clustering:\n",
    "#KMeans:\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto',\n",
    "                verbose=0, random_state=0, copy_x=True, n_jobs=-1,\n",
    "                algorithm='auto').fit(f_data_normalized_no_output)\n",
    "ars_kmeans = adjusted_rand_score(kmeans.labels_, f_data_normalized.Var66)\n",
    "print('K-Means F1: {}'.format(ars_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Adjusted Rand Score: 0.01787080192264462\n",
      "Estimated number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN:\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30,\n",
    "                p=None, n_jobs=None).fit(f_data_normalized_no_output)\n",
    "ars_dbscan = adjusted_rand_score(dbscan.labels_, f_data_normalized.Var66)\n",
    "print('DBSCAN Adjusted Rand Score: {}'.format(ars_dbscan))\n",
    "labels = dbscan.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Adjusted Rand Score: -0.0003935127911477825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BIRCH:\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=2, compute_labels=True, copy=True)\n",
    "brc.fit(f_data_normalized_no_output) \n",
    "ars_birch = adjusted_rand_score(brc.labels_, f_data_normalized.Var66)\n",
    "print('K-Means Adjusted Rand Score: {}'.format(ars_birch))\n",
    "brc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectral = SpectralClustering(n_clusters=2, eigen_solver=None, random_state=0, n_init=10, gamma=1.0, \n",
    "#                              affinity='rbf', n_neighbors=10, eigen_tol=0.0, assign_labels='discretize', degree=3, \n",
    "#                              coef0=1, kernel_params=None, n_jobs=-1).fit(f_data_normalized_no_output)\n",
    "#ars_spectral = adjusted_rand_score(spectral.labels_, f_data_normalized.Var66)\n",
    "#print('K-Means F1: {}'.format(ars_spectral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fin_data_reduced = f_data_merged.copy()\n",
    "fin_data_reduced = fin_data_reduced.drop(columns=['Var7', 'Var22','Var28','Var38','Var60'])#Less dimensions manual\n",
    "\n",
    "fin_data_positive = fin_data_reduced[fin_data_reduced.Var66 == 0]\n",
    "fin_data_negative = fin_data_reduced[fin_data_reduced.Var66 == 1]\n",
    "\n",
    "fin_pos_redu_clean = fin_data_positive.fillna(method='ffill')\n",
    "fin_pos_redu_clean = fin_pos_redu_clean.dropna()\n",
    "fin_neg_redu_clean = fin_data_negative.fillna(method='ffill')\n",
    "fin_neg_redu_clean = fin_neg_redu_clean.dropna()\n",
    "\n",
    "fin_merg_clean = fin_pos_redu_clean.append(fin_neg_redu_clean).sort_index() \n",
    "fin_no_index = fin_merg_clean.drop(columns=['Var1', 'Var66']) #X Training\n",
    "redu_training_y = fin_merg_clean.Var66 #Y training\n",
    "redu_columns_no_index = list(fin_no_index)\n",
    "\n",
    "fin_pos_redu_noutput = fin_pos_redu_clean.drop(columns=['Var66'])\n",
    "fin_neg_redu_nooutput = fin_neg_redu_clean.drop(columns=['Var66'])\n",
    "\n",
    "tes_redu_clean = t_data.fillna(method='bfill').drop(columns=['Var1','Var7', 'Var22','Var28','Var38','Var60'])\n",
    "cID_redu = t_data['Var1'].tolist()\n",
    "tes_redu_columns = list(tes_redu_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>...</th>\n",
       "      <th>Var55</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.047372</td>\n",
       "      <td>-0.673486</td>\n",
       "      <td>0.486074</td>\n",
       "      <td>-0.024099</td>\n",
       "      <td>0.016844</td>\n",
       "      <td>-0.052595</td>\n",
       "      <td>-0.015851</td>\n",
       "      <td>-0.431957</td>\n",
       "      <td>0.401191</td>\n",
       "      <td>-0.078513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056822</td>\n",
       "      <td>-0.048267</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>-0.014587</td>\n",
       "      <td>-0.016036</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>-0.101008</td>\n",
       "      <td>-0.033373</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>-0.087781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.521173</td>\n",
       "      <td>-0.259060</td>\n",
       "      <td>0.018107</td>\n",
       "      <td>-0.064939</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>-0.533961</td>\n",
       "      <td>-0.023774</td>\n",
       "      <td>-0.474901</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>-0.554774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059897</td>\n",
       "      <td>-0.114236</td>\n",
       "      <td>0.012966</td>\n",
       "      <td>-0.082684</td>\n",
       "      <td>-0.011222</td>\n",
       "      <td>-0.016908</td>\n",
       "      <td>-0.009599</td>\n",
       "      <td>-0.018546</td>\n",
       "      <td>-0.296190</td>\n",
       "      <td>-0.092481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.072110</td>\n",
       "      <td>0.304572</td>\n",
       "      <td>-1.225740</td>\n",
       "      <td>-0.084253</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>-0.086073</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>-0.380364</td>\n",
       "      <td>-0.265896</td>\n",
       "      <td>-0.103725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079336</td>\n",
       "      <td>-0.140013</td>\n",
       "      <td>0.013897</td>\n",
       "      <td>-0.016793</td>\n",
       "      <td>-0.015942</td>\n",
       "      <td>-0.016712</td>\n",
       "      <td>-0.096753</td>\n",
       "      <td>-0.008169</td>\n",
       "      <td>-0.331248</td>\n",
       "      <td>-0.094461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.046572</td>\n",
       "      <td>-0.785933</td>\n",
       "      <td>0.468092</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>-0.055495</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.434221</td>\n",
       "      <td>0.684078</td>\n",
       "      <td>-0.081390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054576</td>\n",
       "      <td>0.069027</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>-0.015276</td>\n",
       "      <td>-0.015985</td>\n",
       "      <td>-0.016517</td>\n",
       "      <td>-0.014484</td>\n",
       "      <td>-0.036101</td>\n",
       "      <td>0.812767</td>\n",
       "      <td>-0.084117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.031478</td>\n",
       "      <td>-0.218003</td>\n",
       "      <td>-0.023527</td>\n",
       "      <td>-0.065507</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>-0.027994</td>\n",
       "      <td>-0.024446</td>\n",
       "      <td>-0.442534</td>\n",
       "      <td>0.158998</td>\n",
       "      <td>-0.054107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063208</td>\n",
       "      <td>0.135527</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>-0.010931</td>\n",
       "      <td>-0.015791</td>\n",
       "      <td>-0.016869</td>\n",
       "      <td>-0.103786</td>\n",
       "      <td>-0.027237</td>\n",
       "      <td>-0.213223</td>\n",
       "      <td>-0.088556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var8      Var9  \\\n",
       "0 -0.047372 -0.673486  0.486074 -0.024099  0.016844 -0.052595 -0.015851   \n",
       "1 -0.521173 -0.259060  0.018107 -0.064939  0.016517 -0.533961 -0.023774   \n",
       "2 -0.072110  0.304572 -1.225740 -0.084253  0.015558 -0.086073 -0.026820   \n",
       "3 -0.046572 -0.785933  0.468092  0.011639  0.016791 -0.055495 -0.001097   \n",
       "4 -0.031478 -0.218003 -0.023527 -0.065507  0.016428 -0.027994 -0.024446   \n",
       "\n",
       "      Var10     Var11     Var12  ...     Var55     Var56     Var57     Var58  \\\n",
       "0 -0.431957  0.401191 -0.078513  ... -0.056822 -0.048267  0.015212 -0.014587   \n",
       "1 -0.474901  0.272825 -0.554774  ... -0.059897 -0.114236  0.012966 -0.082684   \n",
       "2 -0.380364 -0.265896 -0.103725  ... -0.079336 -0.140013  0.013897 -0.016793   \n",
       "3 -0.434221  0.684078 -0.081390  ... -0.054576  0.069027  0.015160 -0.015276   \n",
       "4 -0.442534  0.158998 -0.054107  ... -0.063208  0.135527  0.014967 -0.010931   \n",
       "\n",
       "      Var59     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.016036 -0.016834 -0.101008 -0.033373  0.047138 -0.087781  \n",
       "1 -0.011222 -0.016908 -0.009599 -0.018546 -0.296190 -0.092481  \n",
       "2 -0.015942 -0.016712 -0.096753 -0.008169 -0.331248 -0.094461  \n",
       "3 -0.015985 -0.016517 -0.014484 -0.036101  0.812767 -0.084117  \n",
       "4 -0.015791 -0.016869 -0.103786 -0.027237 -0.213223 -0.088556  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>Var12</th>\n",
       "      <th>...</th>\n",
       "      <th>Var55</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111465</td>\n",
       "      <td>-0.059198</td>\n",
       "      <td>0.082161</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>-0.466343</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>0.063263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382460</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.495542</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.082314</td>\n",
       "      <td>-0.123844</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.078187</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>0.326179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073613</td>\n",
       "      <td>-0.086097</td>\n",
       "      <td>0.383066</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>-0.072837</td>\n",
       "      <td>-0.127529</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>-0.166636</td>\n",
       "      <td>-0.003845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.054128</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.059575</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>-0.054489</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>-0.053767</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061990</td>\n",
       "      <td>-0.046986</td>\n",
       "      <td>1.034808</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>-0.086497</td>\n",
       "      <td>-0.075128</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.019013</td>\n",
       "      <td>-0.006665</td>\n",
       "      <td>-0.158136</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.860506</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>-0.068394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084570</td>\n",
       "      <td>-0.330861</td>\n",
       "      <td>0.339624</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>-0.087801</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.227147</td>\n",
       "      <td>-0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.028952</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>-0.049011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051138</td>\n",
       "      <td>-0.045804</td>\n",
       "      <td>-0.074061</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>-0.077897</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.060127</td>\n",
       "      <td>-0.050267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var8      Var9  \\\n",
       "0  0.111465 -0.059198  0.082161  0.070248  0.214767  0.090308 -0.023223   \n",
       "1  0.312120  0.003717  0.016274 -0.129639  0.017576  0.351322 -0.031098   \n",
       "2 -0.040492 -0.054128  0.046884 -0.059575  0.048355 -0.060728 -0.025999   \n",
       "3 -0.052139 -0.019013 -0.006665 -0.158136 -0.398698 -0.072305 -0.030441   \n",
       "4 -0.006261 -0.040289  0.045632 -0.093582  0.032467 -0.026704 -0.028952   \n",
       "\n",
       "      Var10     Var11     Var12  ...     Var55     Var56     Var57     Var58  \\\n",
       "0 -0.466343  0.060784  0.063263  ...  0.382460 -0.081084  0.495542  0.030066   \n",
       "1  0.313527 -0.002135  0.326179  ... -0.073613 -0.086097  0.383066  0.265854   \n",
       "2 -0.054489  0.055714 -0.053767  ... -0.061990 -0.046986  1.034808  0.013795   \n",
       "3 -0.860506  0.020596 -0.068394  ... -0.084570 -0.330861  0.339624  0.013022   \n",
       "4  0.382270  0.041874 -0.049011  ... -0.051138 -0.045804 -0.074061  0.019219   \n",
       "\n",
       "      Var59     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.026149 -0.082314 -0.123844 -0.033871 -0.078187  0.007340  \n",
       "1 -0.026013 -0.072837 -0.127529 -0.025458 -0.166636 -0.003845  \n",
       "2 -0.026707 -0.086497 -0.075128 -0.035621 -0.023507 -0.070540  \n",
       "3 -0.026017 -0.087801 -0.037025  0.051068 -0.227147 -0.084211  \n",
       "4 -0.025604 -0.083841 -0.077897 -0.034567 -0.060127 -0.050267  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "fin_redu_norm = scaler.fit_transform(fin_no_index)\n",
    "fin_redu_normalized = pd.DataFrame(fin_redu_norm, columns=redu_columns_no_index)\n",
    "\n",
    "tes_redu_norm = scaler.fit_transform(tes_redu_clean)\n",
    "tes_redu_normalized = pd.DataFrame(tes_redu_norm, columns=tes_redu_columns)\n",
    "\n",
    "display(fin_redu_normalized.head())\n",
    "display(tes_redu_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3659'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3659, 59)\n",
      "(3659,)\n",
      "(1220, 59)\n",
      "(1220,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(fin_redu_normalized.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_redu_train = fin_redu_normalized.iloc[:index_to_round, :]\n",
    "y_redu_train = redu_training_y.iloc[:index_to_round]\n",
    "\n",
    "x_redu_test = fin_redu_normalized.iloc[index_to_round:, :]\n",
    "y_redu_test = redu_training_y.iloc[index_to_round:]\n",
    "\n",
    "print(x_redu_train.shape)\n",
    "print(y_redu_train.shape)\n",
    "print(x_redu_test.shape)\n",
    "print(y_redu_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9655737704918033\n",
      "Test F1:0.19230769230769232\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.2, n_estimators=1000, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=5,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9622950819672131\n",
      "Test F1:0.041666666666666664\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=20,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9756764143208527 Test Score:0.9573770491803278\n",
      "Test F1:0.16129032258064516\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=1.6, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_reduced.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID_redu, clf.predict(tes_redu_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-sampling:\n",
    "x_full = f_data_normalized.copy()\n",
    "x_maj = x_full[x_full.Var66==0]\n",
    "x_min = x_full[x_full.Var66==1]\n",
    "x_maj_rus = resample(x_maj,replace=False,n_samples=len(x_min),random_state=44)\n",
    "x_rus = pd.concat([x_maj_rus, x_min])\n",
    "x_train_rus = x_rus.drop(columns=['Var66'])\n",
    "y_train_rus = x_rus.Var66\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=42,k_neighbors=5)\n",
    "x_red_tr_sm, y_red_tr_sm = sm.fit_sample(x_redu_train, y_redu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9606557377049181\n",
      "Test F1:0.25\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.2, n_estimators=1000, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=5,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_red_tr_sm, y_red_tr_sm)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.8106557377049181\n",
      "Test F1:0.10116731517509728\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=20,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_red_tr_sm, y_red_tr_sm)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.5996602491506229 Test Score:0.5996602491506229\n",
      "Test F1:0.16129032258064516\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=1.6, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_reduced.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID_redu, clf.predict(tes_redu_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.446426e-17</td>\n",
       "      <td>7.183796e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.541208e-17</td>\n",
       "      <td>4.538853e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.601454e-18</td>\n",
       "      <td>-6.530724e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.405756e-18</td>\n",
       "      <td>-3.510264e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.088169e-17</td>\n",
       "      <td>-9.796086e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pos           neg\n",
       "0  1.446426e-17  7.183796e-18\n",
       "1 -3.541208e-17  4.538853e-17\n",
       "2  6.601454e-18 -6.530724e-18\n",
       "3  1.405756e-18 -3.510264e-18\n",
       "4 -3.088169e-17 -9.796086e-18"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = {'pos': fin_redu_pos_norm.mean().values, 'neg': fin_redu_neg_norm.mean().values}\n",
    "data_mean_df = pd.DataFrame(data=data_mean)\n",
    "data_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means F1: -0.00039304871653265765\n"
     ]
    }
   ],
   "source": [
    "#Clustering:\n",
    "#KMeans:\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto',\n",
    "                verbose=0, random_state=0, copy_x=True, n_jobs=-1,\n",
    "                algorithm='auto').fit(fin_redu_normalized)\n",
    "ars_kmeans = adjusted_rand_score(kmeans.labels_, redu_training_y)\n",
    "print('K-Means F1: {}'.format(ars_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Adjusted Rand Score: 0.01787080192264462\n",
      "Estimated number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN:\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30,\n",
    "                p=None, n_jobs=None).fit(f_data_normalized_no_output)\n",
    "ars_dbscan = adjusted_rand_score(dbscan.labels_, f_data_normalized.Var66)\n",
    "print('DBSCAN Adjusted Rand Score: {}'.format(ars_dbscan))\n",
    "labels = dbscan.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Adjusted Rand Score: -0.0003935127911477825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BIRCH:\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=2, compute_labels=True, copy=True)\n",
    "brc.fit(f_data_normalized_no_output) \n",
    "ars_birch = adjusted_rand_score(brc.labels_, f_data_normalized.Var66)\n",
    "print('K-Means Adjusted Rand Score: {}'.format(ars_birch))\n",
    "brc.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
