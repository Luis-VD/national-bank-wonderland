{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CS5228 project\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# visualiation\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# model training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier # decision Tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_selection import RFE # for feature selection of LR\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_threshold_selector(data, threshold=0.5):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.150120</td>\n",
       "      <td>0.395670</td>\n",
       "      <td>3.63570</td>\n",
       "      <td>54.043</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>0.031029</td>\n",
       "      <td>4.56831</td>\n",
       "      <td>1.01120</td>\n",
       "      <td>...</td>\n",
       "      <td>3871.001</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.034914</td>\n",
       "      <td>0.98896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>5.8248</td>\n",
       "      <td>34.713</td>\n",
       "      <td>10.5150</td>\n",
       "      <td>3.4752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15092</td>\n",
       "      <td>0.049699</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.726800</td>\n",
       "      <td>12.94400</td>\n",
       "      <td>233.110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063192</td>\n",
       "      <td>14.19601</td>\n",
       "      <td>0.89618</td>\n",
       "      <td>...</td>\n",
       "      <td>8751.901</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>0.93169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0492</td>\n",
       "      <td>11.1520</td>\n",
       "      <td>24.784</td>\n",
       "      <td>14.7270</td>\n",
       "      <td>4.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19821</td>\n",
       "      <td>-0.356310</td>\n",
       "      <td>0.392880</td>\n",
       "      <td>0.158840</td>\n",
       "      <td>1.40430</td>\n",
       "      <td>-2.619</td>\n",
       "      <td>-0.085597</td>\n",
       "      <td>-0.356320</td>\n",
       "      <td>1.54531</td>\n",
       "      <td>0.92963</td>\n",
       "      <td>...</td>\n",
       "      <td>44.859</td>\n",
       "      <td>-0.172770</td>\n",
       "      <td>-0.586910</td>\n",
       "      <td>1.38330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.6112</td>\n",
       "      <td>15.7790</td>\n",
       "      <td>154.260</td>\n",
       "      <td>2.3662</td>\n",
       "      <td>2.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14171</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.708110</td>\n",
       "      <td>-0.052312</td>\n",
       "      <td>0.88978</td>\n",
       "      <td>-31.198</td>\n",
       "      <td>0.269520</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.41222</td>\n",
       "      <td>1.96540</td>\n",
       "      <td>...</td>\n",
       "      <td>-331.879</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>0.745480</td>\n",
       "      <td>17.1011</td>\n",
       "      <td>7.9482</td>\n",
       "      <td>88.147</td>\n",
       "      <td>4.1408</td>\n",
       "      <td>3.4021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.346520</td>\n",
       "      <td>0.335930</td>\n",
       "      <td>2.76130</td>\n",
       "      <td>39.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>1.88591</td>\n",
       "      <td>1.29750</td>\n",
       "      <td>...</td>\n",
       "      <td>38170.001</td>\n",
       "      <td>0.212410</td>\n",
       "      <td>0.030652</td>\n",
       "      <td>0.80158</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>9.7670</td>\n",
       "      <td>6.7570</td>\n",
       "      <td>53.651</td>\n",
       "      <td>6.8032</td>\n",
       "      <td>2.7412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2      Var3      Var4      Var5     Var6      Var7      Var8  \\\n",
       "0  18399  0.023954  0.150120  0.395670   3.63570   54.043  0.028822  0.031029   \n",
       "1  15092  0.049699  0.065808  0.726800  12.94400  233.110  0.000000  0.063192   \n",
       "2  19821 -0.356310  0.392880  0.158840   1.40430   -2.619 -0.085597 -0.356320   \n",
       "3  14171  0.001417  0.708110 -0.052312   0.88978  -31.198  0.269520  0.001407   \n",
       "4  12900  0.020041  0.346520  0.335930   2.76130   39.050  0.000000  0.020031   \n",
       "\n",
       "       Var9    Var10  ...      Var56     Var57     Var58    Var59     Var60  \\\n",
       "0   4.56831  1.01120  ...   3871.001  0.011041  0.034914  0.98896  0.000000   \n",
       "1  14.19601  0.89618  ...   8751.901  0.059565  0.053189  0.93169  0.000000   \n",
       "2   1.54531  0.92963  ...     44.859 -0.172770 -0.586910  1.38330  0.000000   \n",
       "3   0.41222  1.96540  ...   -331.879 -0.000535  0.004820  0.99930  0.745480   \n",
       "4   1.88591  1.29750  ...  38170.001  0.212410  0.030652  0.80158  0.000862   \n",
       "\n",
       "     Var61    Var62    Var63    Var64   Var65  \n",
       "0   9.5214   5.8248   34.713  10.5150  3.4752  \n",
       "1   5.0492  11.1520   24.784  14.7270  4.2204  \n",
       "2   5.6112  15.7790  154.260   2.3662  2.0738  \n",
       "3  17.1011   7.9482   88.147   4.1408  3.4021  \n",
       "4   9.7670   6.7570   53.651   6.8032  2.7412  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15260</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>0.13924</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>6.96220</td>\n",
       "      <td>473.710</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>6.18171</td>\n",
       "      <td>0.79295</td>\n",
       "      <td>...</td>\n",
       "      <td>617.791</td>\n",
       "      <td>0.283210</td>\n",
       "      <td>0.125470</td>\n",
       "      <td>0.73116</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.7199</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>64.095</td>\n",
       "      <td>5.69470</td>\n",
       "      <td>25.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14798</td>\n",
       "      <td>0.236630</td>\n",
       "      <td>0.86496</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>1.08490</td>\n",
       "      <td>-18.866</td>\n",
       "      <td>-0.90779</td>\n",
       "      <td>0.276330</td>\n",
       "      <td>0.15613</td>\n",
       "      <td>2.14410</td>\n",
       "      <td>...</td>\n",
       "      <td>156.161</td>\n",
       "      <td>0.228270</td>\n",
       "      <td>1.752300</td>\n",
       "      <td>0.79460</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>22.7391</td>\n",
       "      <td>3.2655</td>\n",
       "      <td>142.160</td>\n",
       "      <td>2.56760</td>\n",
       "      <td>22.79400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16288</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.19772</td>\n",
       "      <td>0.423630</td>\n",
       "      <td>3.14500</td>\n",
       "      <td>58.018</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>4.05761</td>\n",
       "      <td>1.50650</td>\n",
       "      <td>...</td>\n",
       "      <td>3758.001</td>\n",
       "      <td>0.546620</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>0.47022</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.9728</td>\n",
       "      <td>6.4937</td>\n",
       "      <td>47.851</td>\n",
       "      <td>7.62790</td>\n",
       "      <td>3.97500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14843</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.60277</td>\n",
       "      <td>-0.193510</td>\n",
       "      <td>0.24701</td>\n",
       "      <td>-1058.700</td>\n",
       "      <td>-0.00317</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>0.11005</td>\n",
       "      <td>...</td>\n",
       "      <td>-22384.999</td>\n",
       "      <td>0.207050</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.79303</td>\n",
       "      <td>0.87049</td>\n",
       "      <td>2.1823</td>\n",
       "      <td>8.8410</td>\n",
       "      <td>852.310</td>\n",
       "      <td>0.42825</td>\n",
       "      <td>0.11752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16200</td>\n",
       "      <td>0.032548</td>\n",
       "      <td>0.35735</td>\n",
       "      <td>0.409210</td>\n",
       "      <td>2.14510</td>\n",
       "      <td>18.331</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>1.79841</td>\n",
       "      <td>2.26320</td>\n",
       "      <td>...</td>\n",
       "      <td>3866.801</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.050632</td>\n",
       "      <td>0.98583</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.6220</td>\n",
       "      <td>6.3231</td>\n",
       "      <td>57.632</td>\n",
       "      <td>6.33320</td>\n",
       "      <td>9.69520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1      Var2     Var3      Var4     Var5      Var6     Var7      Var8  \\\n",
       "0  15260  0.108010  0.13924  0.830200  6.96220   473.710  0.00000  0.108000   \n",
       "1  14798  0.236630  0.86496  0.070858  1.08490   -18.866 -0.90779  0.276330   \n",
       "2  16288  0.010606  0.19772  0.423630  3.14500    58.018  0.00000  0.010596   \n",
       "3  14843  0.003140  0.60277 -0.193510  0.24701 -1058.700 -0.00317  0.003130   \n",
       "4  16200  0.032548  0.35735  0.409210  2.14510    18.331  0.00000  0.032538   \n",
       "\n",
       "      Var9    Var10  ...      Var56     Var57     Var58    Var59    Var60  \\\n",
       "0  6.18171  0.79295  ...    617.791  0.283210  0.125470  0.73116  0.00000   \n",
       "1  0.15613  2.14410  ...    156.161  0.228270  1.752300  0.79460  0.00000   \n",
       "2  4.05761  1.50650  ...   3758.001  0.546620  0.013208  0.47022  0.00000   \n",
       "3  0.65900  0.11005  ... -22384.999  0.207050  0.007880  0.79303  0.87049   \n",
       "4  1.79841  2.26320  ...   3866.801  0.004981  0.050632  0.98583  0.00000   \n",
       "\n",
       "     Var61   Var62    Var63    Var64     Var65  \n",
       "0   9.7199  3.4925   64.095  5.69470  25.95000  \n",
       "1  22.7391  3.2655  142.160  2.56760  22.79400  \n",
       "2   3.9728  6.4937   47.851  7.62790   3.97500  \n",
       "3   2.1823  8.8410  852.310  0.42825   0.11752  \n",
       "4   7.6220  6.3231   57.632  6.33320   9.69520  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Var1  Var66\n",
       "0  18399      0\n",
       "1  19821      0\n",
       "2  17769      0\n",
       "3  19309      0\n",
       "4  20728      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load into dataframe\n",
    "f_data = pd.read_csv('financial_data.csv', na_values=['?']) \n",
    "revealed = pd.read_csv('revealed_businesses.csv')\n",
    "t_data = pd.read_csv('testing_data.csv', na_values=['?'])\n",
    "\n",
    "display(f_data.head())\n",
    "display(t_data.head())\n",
    "display(revealed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "#display(f_data.isna().sum().sort_values(ascending=False))\n",
    "#f_data_2 = f_data.drop(columns=['Var38', 'Var22', 'Var61', 'Var28', 'Var61']) #Use in case of column reduction\n",
    "#columns_no_output = list(f_data_2)  #Use in case of column reduction\n",
    "#t_data_reduced = t_data[columns_no_output]\n",
    "f_data_merged = f_data.merge(revealed)\n",
    "f_data_revealed = f_data_merged[f_data_merged.Var66 != np.nan]\n",
    "\n",
    "f_data_positive = f_data_revealed[f_data_revealed.Var66 == 0]\n",
    "f_data_negative = f_data_revealed[f_data_revealed.Var66 == 1]\n",
    "\n",
    "f_data_positive_clean = f_data_positive.fillna(method='ffill')\n",
    "f_data_positive_clean = f_data_positive_clean.dropna()\n",
    "f_data_negative_clean = f_data_negative.fillna(method='ffill')\n",
    "f_data_negative_clean = f_data_negative_clean.dropna()\n",
    "\n",
    "f_data_merged_clean = f_data_positive_clean.append(f_data_negative_clean).sort_index() \n",
    "f_data_no_index = f_data_merged_clean.drop(columns=['Var1', 'Var66']) #X Training\n",
    "training_y = f_data_merged_clean.Var66 #Y training\n",
    "columns_no_index = list(f_data_no_index)\n",
    "\n",
    "f_data_positive_no_output = f_data_positive_clean.drop(columns=['Var66'])\n",
    "f_data_negative_no_output = f_data_negative_clean.drop(columns=['Var66'])\n",
    "\n",
    "t_data_clean = t_data.fillna(method='bfill').drop(columns=['Var1'])\n",
    "cID = t_data['Var1'].tolist()\n",
    "t_data_columns = list(t_data_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#f_data_limited = variance_threshold_selector(f_data_no_index_no_outliers, 0.8) #x for training\n",
    "#f_data_limited_output = f_data_limited.copy(deep='true')\n",
    "#f_data_limited_output['Var66'] = training_y\n",
    "#columns_no_index_limited = list(f_data_limited_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(f_data.isna().sum())\n",
    "#display(f_data_merged_clean.isnull().sum())\n",
    "#display(f_data_revealed.isnull().sum())\n",
    "#display(f_data_merged_clean.Var66)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.031578</td>\n",
       "      <td>-0.217947</td>\n",
       "      <td>-0.023833</td>\n",
       "      <td>-0.065522</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>-0.028107</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.442741</td>\n",
       "      <td>0.158892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>-0.038823</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.103804</td>\n",
       "      <td>-0.027241</td>\n",
       "      <td>-0.213160</td>\n",
       "      <td>-0.088586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.114623</td>\n",
       "      <td>0.474405</td>\n",
       "      <td>-0.028456</td>\n",
       "      <td>-0.069338</td>\n",
       "      <td>0.016689</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.128480</td>\n",
       "      <td>-0.027264</td>\n",
       "      <td>-0.020177</td>\n",
       "      <td>-0.428242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.015734</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>-0.134625</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>-0.303888</td>\n",
       "      <td>0.043696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.310244</td>\n",
       "      <td>0.519723</td>\n",
       "      <td>-0.142454</td>\n",
       "      <td>-0.065566</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.323589</td>\n",
       "      <td>-0.027363</td>\n",
       "      <td>-0.643001</td>\n",
       "      <td>-0.471554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104362</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.154133</td>\n",
       "      <td>-0.012374</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>-0.016767</td>\n",
       "      <td>-0.122845</td>\n",
       "      <td>-0.022144</td>\n",
       "      <td>-0.273064</td>\n",
       "      <td>-0.096589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.147664</td>\n",
       "      <td>0.124218</td>\n",
       "      <td>-0.853632</td>\n",
       "      <td>-0.081879</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.164845</td>\n",
       "      <td>-0.026206</td>\n",
       "      <td>-0.364337</td>\n",
       "      <td>-0.093558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156144</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>-0.015302</td>\n",
       "      <td>-0.044719</td>\n",
       "      <td>-0.016792</td>\n",
       "      <td>-0.088503</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>-0.307144</td>\n",
       "      <td>-0.094299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.187001</td>\n",
       "      <td>0.803238</td>\n",
       "      <td>-0.805485</td>\n",
       "      <td>-0.077174</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.017261</td>\n",
       "      <td>-0.200669</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>0.742657</td>\n",
       "      <td>-0.742599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147965</td>\n",
       "      <td>0.014853</td>\n",
       "      <td>0.613947</td>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.194292</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>-0.110785</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.256083</td>\n",
       "      <td>-0.060590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0 -0.031578 -0.217947 -0.023833 -0.065522  0.016436  0.043052 -0.028107   \n",
       "1 -0.114623  0.474405 -0.028456 -0.069338  0.016689  0.017261 -0.128480   \n",
       "2 -0.310244  0.519723 -0.142454 -0.065566  0.016455  0.017261 -0.323589   \n",
       "3 -0.147664  0.124218 -0.853632 -0.081879  0.015869  0.017261 -0.164845   \n",
       "4 -0.187001  0.803238 -0.805485 -0.077174  0.022185  0.017261 -0.200669   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.024453 -0.442741  0.158892  ...  0.135385  0.014975 -0.010964 -0.015799   \n",
       "1 -0.027264 -0.020177 -0.428242  ... -0.114428  0.014054 -0.036933 -0.015734   \n",
       "2 -0.027363 -0.643001 -0.471554  ... -0.104362  0.011261 -0.154133 -0.012374   \n",
       "3 -0.026206 -0.364337 -0.093558  ... -0.156144  0.014151 -0.034607 -0.015302   \n",
       "4 -0.027868  0.742657 -0.742599  ... -0.147965  0.014853  0.613947 -0.015536   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.038823 -0.016877 -0.103804 -0.027241 -0.213160 -0.088586  \n",
       "1 -0.044719 -0.016877 -0.134625 -0.016933 -0.303888  0.043696  \n",
       "2  0.028404 -0.016767 -0.122845 -0.022144 -0.273064 -0.096589  \n",
       "3 -0.044719 -0.016792 -0.088503 -0.016169 -0.307144 -0.094299  \n",
       "4 -0.194292  0.001046 -0.110785 -0.024033 -0.256083 -0.060590  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var56</th>\n",
       "      <th>Var57</th>\n",
       "      <th>Var58</th>\n",
       "      <th>Var59</th>\n",
       "      <th>Var60</th>\n",
       "      <th>Var61</th>\n",
       "      <th>Var62</th>\n",
       "      <th>Var63</th>\n",
       "      <th>Var64</th>\n",
       "      <th>Var65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111465</td>\n",
       "      <td>-0.059198</td>\n",
       "      <td>0.082161</td>\n",
       "      <td>0.070248</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>0.090308</td>\n",
       "      <td>-0.023223</td>\n",
       "      <td>-0.466343</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081084</td>\n",
       "      <td>0.495542</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>-0.026149</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.082314</td>\n",
       "      <td>-0.123844</td>\n",
       "      <td>-0.033871</td>\n",
       "      <td>-0.078187</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.312120</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.129639</td>\n",
       "      <td>0.017576</td>\n",
       "      <td>-0.046425</td>\n",
       "      <td>0.351322</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.313527</td>\n",
       "      <td>-0.002135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086097</td>\n",
       "      <td>0.383066</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>-0.026013</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.072837</td>\n",
       "      <td>-0.127529</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>-0.166636</td>\n",
       "      <td>-0.003845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.040492</td>\n",
       "      <td>-0.054128</td>\n",
       "      <td>0.046884</td>\n",
       "      <td>-0.059575</td>\n",
       "      <td>0.048355</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.060728</td>\n",
       "      <td>-0.025999</td>\n",
       "      <td>-0.054489</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046986</td>\n",
       "      <td>1.034808</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.086497</td>\n",
       "      <td>-0.075128</td>\n",
       "      <td>-0.035621</td>\n",
       "      <td>-0.023507</td>\n",
       "      <td>-0.070540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052139</td>\n",
       "      <td>-0.019013</td>\n",
       "      <td>-0.006665</td>\n",
       "      <td>-0.158136</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>-0.072305</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.860506</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330861</td>\n",
       "      <td>0.339624</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>-0.026017</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>-0.087801</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>0.051068</td>\n",
       "      <td>-0.227147</td>\n",
       "      <td>-0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.045632</td>\n",
       "      <td>-0.093582</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.025733</td>\n",
       "      <td>-0.026704</td>\n",
       "      <td>-0.028952</td>\n",
       "      <td>0.382270</td>\n",
       "      <td>0.041874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045804</td>\n",
       "      <td>-0.074061</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.058331</td>\n",
       "      <td>-0.083841</td>\n",
       "      <td>-0.077897</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>-0.060127</td>\n",
       "      <td>-0.050267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var2      Var3      Var4      Var5      Var6      Var7      Var8  \\\n",
       "0  0.111465 -0.059198  0.082161  0.070248  0.214767  0.025733  0.090308   \n",
       "1  0.312120  0.003717  0.016274 -0.129639  0.017576 -0.046425  0.351322   \n",
       "2 -0.040492 -0.054128  0.046884 -0.059575  0.048355  0.025733 -0.060728   \n",
       "3 -0.052139 -0.019013 -0.006665 -0.158136 -0.398698  0.025481 -0.072305   \n",
       "4 -0.006261 -0.040289  0.045632 -0.093582  0.032467  0.025733 -0.026704   \n",
       "\n",
       "       Var9     Var10     Var11  ...     Var56     Var57     Var58     Var59  \\\n",
       "0 -0.023223 -0.466343  0.060784  ... -0.081084  0.495542  0.030066 -0.026149   \n",
       "1 -0.031098  0.313527 -0.002135  ... -0.086097  0.383066  0.265854 -0.026013   \n",
       "2 -0.025999 -0.054489  0.055714  ... -0.046986  1.034808  0.013795 -0.026707   \n",
       "3 -0.030441 -0.860506  0.020596  ... -0.330861  0.339624  0.013022 -0.026017   \n",
       "4 -0.028952  0.382270  0.041874  ... -0.045804 -0.074061  0.019219 -0.025604   \n",
       "\n",
       "      Var60     Var61     Var62     Var63     Var64     Var65  \n",
       "0 -0.058331 -0.082314 -0.123844 -0.033871 -0.078187  0.007340  \n",
       "1 -0.058331 -0.072837 -0.127529 -0.025458 -0.166636 -0.003845  \n",
       "2 -0.058331 -0.086497 -0.075128 -0.035621 -0.023507 -0.070540  \n",
       "3  0.017325 -0.087801 -0.037025  0.051068 -0.227147 -0.084211  \n",
       "4 -0.058331 -0.083841 -0.077897 -0.034567 -0.060127 -0.050267  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "f_data_norm = scaler.fit_transform(f_data_no_index)\n",
    "f_data_normalized = pd.DataFrame(f_data_norm, columns=columns_no_index)\n",
    "\n",
    "t_data_norm = scaler.fit_transform(t_data_clean)\n",
    "t_data_normalized = pd.DataFrame(t_data_norm, columns=t_data_columns)\n",
    "\n",
    "display(f_data_normalized.head())\n",
    "display(t_data_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3656'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 64)\n",
      "(3656,)\n",
      "(1218, 64)\n",
      "(1218,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(f_data_normalized.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_training = f_data_normalized.iloc[:index_to_round, :]\n",
    "y_training = training_y.iloc[:index_to_round]\n",
    "\n",
    "\n",
    "x_testing = f_data_normalized.iloc[index_to_round:, :]\n",
    "y_testing = training_y.iloc[index_to_round:]\n",
    "\n",
    "print(x_training.shape)\n",
    "print(y_training.shape)\n",
    "print(x_testing.shape)\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.987417943107221 Test Score:0.958128078817734\n",
      "Test F1:0.13559322033898305\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9669037199124726 Test Score:0.9655172413793104\n",
      "Test F1:0.04545454545454545\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                           p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9729212253829321 Test Score:0.9655172413793104\n",
      "Test F1:0.22222222222222218\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=65, learning_rate=1, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_training, y_training)\n",
    "train_score = clf.score(x_training, y_training)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_basic.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=42)\n",
    "x_train_sm, y_train_sm = sm.fit_sample(x_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9573070607553367\n",
      "Test F1:0.31578947368421056\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.3, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_train_sm, y_train_sm)\n",
    "train_score = clf.score(x_train_sm, y_train_sm)\n",
    "test_score = clf.score(x_testing, y_testing)\n",
    "test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_upsampled.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID, clf.predict(t_data_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means F1: -0.0003935127911477825\n"
     ]
    }
   ],
   "source": [
    "#Clustering:\n",
    "#KMeans:\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto',\n",
    "                verbose=0, random_state=0, copy_x=True, n_jobs=-1,\n",
    "                algorithm='auto').fit(f_data_normalized)\n",
    "ars_kmeans = adjusted_rand_score(kmeans.labels_, training_y)\n",
    "print('K-Means F1: {}'.format(ars_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Adjusted Rand Score: 0.01787080192264462\n",
      "Estimated number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN:\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30,\n",
    "                p=None, n_jobs=None).fit(f_data_normalized)\n",
    "ars_dbscan = adjusted_rand_score(dbscan.labels_, training_y)\n",
    "print('DBSCAN Adjusted Rand Score: {}'.format(ars_dbscan))\n",
    "labels = dbscan.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Adjusted Rand Score: -0.0003935127911477825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BIRCH:\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=2, compute_labels=True, copy=True)\n",
    "brc.fit(f_data_normalized) \n",
    "ars_birch = adjusted_rand_score(brc.labels_, training_y)\n",
    "print('K-Means Adjusted Rand Score: {}'.format(ars_birch))\n",
    "brc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spectral = SpectralClustering(n_clusters=2, eigen_solver=None, random_state=0, n_init=10, gamma=1.0, \n",
    "#                              affinity='rbf', n_neighbors=10, eigen_tol=0.0, assign_labels='discretize', degree=3, \n",
    "#                              coef0=1, kernel_params=None, n_jobs=-1).fit(f_data_normalized_no_output)\n",
    "#ars_spectral = adjusted_rand_score(spectral.labels_, f_data_normalized.Var66)\n",
    "#print('K-Means F1: {}'.format(ars_spectral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fin_data_reduced = f_data_merged.copy()\n",
    "fin_data_reduced = fin_data_reduced[['Var1','Var6',\n",
    "'Var22',\n",
    "'Var25',\n",
    "'Var28',\n",
    "'Var31',\n",
    "'Var35',\n",
    "'Var38',\n",
    "'Var43',\n",
    "'Var47',\n",
    "'Var58','Var66']]#Less dimensions manual\n",
    "\n",
    "fin_data_positive = fin_data_reduced[fin_data_reduced.Var66 == 0]\n",
    "fin_data_negative = fin_data_reduced[fin_data_reduced.Var66 == 1]\n",
    "\n",
    "fin_pos_redu_clean = fin_data_positive.fillna(method='ffill')\n",
    "fin_pos_redu_clean = fin_pos_redu_clean.dropna()\n",
    "fin_neg_redu_clean = fin_data_negative.fillna(method='ffill')\n",
    "fin_neg_redu_clean = fin_neg_redu_clean.dropna()\n",
    "\n",
    "fin_merg_clean = fin_pos_redu_clean.append(fin_neg_redu_clean).sort_index() \n",
    "fin_no_index = fin_merg_clean.drop(columns=['Var1', 'Var66']) #X Training\n",
    "redu_training_y = fin_merg_clean.Var66 #Y training\n",
    "redu_columns_no_index = list(fin_no_index)\n",
    "\n",
    "fin_pos_redu_noutput = fin_pos_redu_clean.drop(columns=['Var66'])\n",
    "fin_neg_redu_nooutput = fin_neg_redu_clean.drop(columns=['Var66'])\n",
    "\n",
    "tes_redu_clean = t_data.fillna(method='bfill')[['Var6',\n",
    "'Var22',\n",
    "'Var25',\n",
    "'Var28',\n",
    "'Var31',\n",
    "'Var35',\n",
    "'Var38',\n",
    "'Var43',\n",
    "'Var47',\n",
    "'Var58']]\n",
    "cID_redu = t_data['Var1'].tolist()\n",
    "tes_redu_columns = list(tes_redu_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Normalizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var31</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var43</th>\n",
       "      <th>Var47</th>\n",
       "      <th>Var58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016436</td>\n",
       "      <td>-0.014356</td>\n",
       "      <td>-0.170099</td>\n",
       "      <td>-0.032774</td>\n",
       "      <td>-0.027993</td>\n",
       "      <td>-0.069315</td>\n",
       "      <td>-0.091150</td>\n",
       "      <td>0.015769</td>\n",
       "      <td>-0.060031</td>\n",
       "      <td>-0.010964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016689</td>\n",
       "      <td>-0.015078</td>\n",
       "      <td>-0.419056</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>-0.042966</td>\n",
       "      <td>-0.091150</td>\n",
       "      <td>0.016150</td>\n",
       "      <td>-0.053290</td>\n",
       "      <td>-0.036933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016455</td>\n",
       "      <td>-0.014965</td>\n",
       "      <td>-0.410419</td>\n",
       "      <td>-0.032881</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>-0.058322</td>\n",
       "      <td>-0.102177</td>\n",
       "      <td>-0.005938</td>\n",
       "      <td>-0.053474</td>\n",
       "      <td>-0.154133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.014120</td>\n",
       "      <td>-0.281341</td>\n",
       "      <td>-0.032818</td>\n",
       "      <td>-0.017145</td>\n",
       "      <td>-0.047044</td>\n",
       "      <td>-0.102177</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>-0.069587</td>\n",
       "      <td>-0.034607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022185</td>\n",
       "      <td>-0.014487</td>\n",
       "      <td>-0.246772</td>\n",
       "      <td>-0.032827</td>\n",
       "      <td>-0.025876</td>\n",
       "      <td>-0.033207</td>\n",
       "      <td>-0.057627</td>\n",
       "      <td>0.015719</td>\n",
       "      <td>-0.061489</td>\n",
       "      <td>0.613947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var6     Var22     Var25     Var28     Var31     Var35     Var38  \\\n",
       "0  0.016436 -0.014356 -0.170099 -0.032774 -0.027993 -0.069315 -0.091150   \n",
       "1  0.016689 -0.015078 -0.419056 -0.032773 -0.022937 -0.042966 -0.091150   \n",
       "2  0.016455 -0.014965 -0.410419 -0.032881  0.015977 -0.058322 -0.102177   \n",
       "3  0.015869 -0.014120 -0.281341 -0.032818 -0.017145 -0.047044 -0.102177   \n",
       "4  0.022185 -0.014487 -0.246772 -0.032827 -0.025876 -0.033207 -0.057627   \n",
       "\n",
       "      Var43     Var47     Var58  \n",
       "0  0.015769 -0.060031 -0.010964  \n",
       "1  0.016150 -0.053290 -0.036933  \n",
       "2 -0.005938 -0.053474 -0.154133  \n",
       "3  0.014248 -0.069587 -0.034607  \n",
       "4  0.015719 -0.061489  0.613947  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var22</th>\n",
       "      <th>Var25</th>\n",
       "      <th>Var28</th>\n",
       "      <th>Var31</th>\n",
       "      <th>Var35</th>\n",
       "      <th>Var38</th>\n",
       "      <th>Var43</th>\n",
       "      <th>Var47</th>\n",
       "      <th>Var58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.057908</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>-0.028689</td>\n",
       "      <td>-0.052617</td>\n",
       "      <td>-0.002824</td>\n",
       "      <td>-0.057015</td>\n",
       "      <td>-0.055392</td>\n",
       "      <td>0.081260</td>\n",
       "      <td>0.030066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017576</td>\n",
       "      <td>-0.027669</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>-0.028689</td>\n",
       "      <td>-0.017191</td>\n",
       "      <td>-0.156732</td>\n",
       "      <td>-0.057015</td>\n",
       "      <td>0.058890</td>\n",
       "      <td>-0.104671</td>\n",
       "      <td>0.265854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048355</td>\n",
       "      <td>-0.027669</td>\n",
       "      <td>-0.012102</td>\n",
       "      <td>-0.055557</td>\n",
       "      <td>-0.025364</td>\n",
       "      <td>-0.048500</td>\n",
       "      <td>-0.057015</td>\n",
       "      <td>-0.055392</td>\n",
       "      <td>-0.095968</td>\n",
       "      <td>0.013795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.398698</td>\n",
       "      <td>-0.038355</td>\n",
       "      <td>-0.150629</td>\n",
       "      <td>-0.055336</td>\n",
       "      <td>0.160550</td>\n",
       "      <td>-0.289406</td>\n",
       "      <td>-0.057015</td>\n",
       "      <td>0.136828</td>\n",
       "      <td>-0.131278</td>\n",
       "      <td>0.013022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032467</td>\n",
       "      <td>-0.038355</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>-0.053301</td>\n",
       "      <td>-0.025997</td>\n",
       "      <td>0.158755</td>\n",
       "      <td>-0.056948</td>\n",
       "      <td>-0.041871</td>\n",
       "      <td>-0.092896</td>\n",
       "      <td>0.019219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Var6     Var22     Var25     Var28     Var31     Var35     Var38  \\\n",
       "0  0.214767  0.057908  0.084262 -0.028689 -0.052617 -0.002824 -0.057015   \n",
       "1  0.017576 -0.027669  0.084262 -0.028689 -0.017191 -0.156732 -0.057015   \n",
       "2  0.048355 -0.027669 -0.012102 -0.055557 -0.025364 -0.048500 -0.057015   \n",
       "3 -0.398698 -0.038355 -0.150629 -0.055336  0.160550 -0.289406 -0.057015   \n",
       "4  0.032467 -0.038355  0.065768 -0.053301 -0.025997  0.158755 -0.056948   \n",
       "\n",
       "      Var43     Var47     Var58  \n",
       "0 -0.055392  0.081260  0.030066  \n",
       "1  0.058890 -0.104671  0.265854  \n",
       "2 -0.055392 -0.095968  0.013795  \n",
       "3  0.136828 -0.131278  0.013022  \n",
       "4 -0.041871 -0.092896  0.019219  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "fin_redu_norm = scaler.fit_transform(fin_no_index)\n",
    "fin_redu_normalized = pd.DataFrame(fin_redu_norm, columns=redu_columns_no_index)\n",
    "\n",
    "tes_redu_norm = scaler.fit_transform(tes_redu_clean)\n",
    "tes_redu_normalized = pd.DataFrame(tes_redu_norm, columns=tes_redu_columns)\n",
    "\n",
    "display(fin_redu_normalized.head())\n",
    "display(tes_redu_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset will be split on index: 3656'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3656, 10)\n",
      "(3656,)\n",
      "(1218, 10)\n",
      "(1218,)\n"
     ]
    }
   ],
   "source": [
    "#Set Splitting\n",
    "index_to_round = round(len(fin_redu_normalized.index)*0.75)\n",
    "display(\"Dataset will be split on index: {}\".format(index_to_round))\n",
    "\n",
    "x_redu_train = fin_redu_normalized.iloc[:index_to_round, :]\n",
    "y_redu_train = redu_training_y.iloc[:index_to_round]\n",
    "\n",
    "x_redu_test = fin_redu_normalized.iloc[index_to_round:, :]\n",
    "y_redu_test = redu_training_y.iloc[index_to_round:]\n",
    "\n",
    "print(x_redu_train.shape)\n",
    "print(y_redu_train.shape)\n",
    "print(x_redu_test.shape)\n",
    "print(y_redu_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9696223316912972\n",
      "Test F1:0.3018867924528302\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.2, n_estimators=1000, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=5,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9622331691297209\n",
      "Test F1:0.11538461538461539\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=20,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.9781181619256017 Test Score:0.9655172413793104\n",
      "Test F1:0.22222222222222218\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=1.6, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_redu_train, y_redu_train)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_reduced.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID_redu, clf.predict(tes_redu_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE Re-Sampling:\n",
    "sm = SMOTE(random_state=42,k_neighbors=5)\n",
    "x_red_tr_sm, y_red_tr_sm = sm.fit_sample(x_redu_train, y_redu_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.9557377049180328\n",
      "Test F1:0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.2, n_estimators=1000, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=5,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "clf.fit(x_red_tr_sm, y_red_tr_sm)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:1.0 Test Score:0.8106557377049181\n",
      "Test F1:0.10116731517509728\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3, weights='distance', algorithm='auto', leaf_size=20,\n",
    "                           p=1, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "clf.fit(x_red_tr_sm, y_red_tr_sm)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_redu_test, y_redu_test)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:0.5996602491506229 Test Score:0.5996602491506229\n",
      "Test F1:0.16129032258064516\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=100, learning_rate=1.6, algorithm='SAMME.R', random_state=None)\n",
    "clf.fit(x_redu_train, y_redu_train)\n",
    "train_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_score = clf.score(x_red_tr_sm, y_red_tr_sm)\n",
    "test_f1 = f1_score(y_redu_test, clf.predict(x_redu_test))\n",
    "print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results to predictions.csv\n",
    "f = open('predictions_reduced.csv', 'w')\n",
    "f.write('Business_ID,Is_Bankrupted\\n')\n",
    "for a,b in zip(cID_redu, clf.predict(tes_redu_normalized)):\n",
    "    f.write(str(a))\n",
    "    f.write(',')\n",
    "    f.write(str(round(b)))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means F1: -0.00039304871653265765\n"
     ]
    }
   ],
   "source": [
    "#Clustering:\n",
    "#KMeans:\n",
    "kmeans = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto',\n",
    "                verbose=0, random_state=0, copy_x=True, n_jobs=-1,\n",
    "                algorithm='auto').fit(fin_redu_normalized)\n",
    "ars_kmeans = adjusted_rand_score(kmeans.labels_, redu_training_y)\n",
    "print('K-Means F1: {}'.format(ars_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Adjusted Rand Score: 0.01787080192264462\n",
      "Estimated number of clusters: 2\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN:\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30,\n",
    "                p=None, n_jobs=None).fit(f_data_normalized)\n",
    "ars_dbscan = adjusted_rand_score(dbscan.labels_, training_y)\n",
    "print('DBSCAN Adjusted Rand Score: {}'.format(ars_dbscan))\n",
    "labels = dbscan.labels_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means Adjusted Rand Score: -0.0003935127911477825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BIRCH:\n",
    "brc = Birch(threshold=0.5, branching_factor=50, n_clusters=2, compute_labels=True, copy=True)\n",
    "brc.fit(f_data_normalized) \n",
    "ars_birch = adjusted_rand_score(brc.labels_, training_y)\n",
    "print('K-Means Adjusted Rand Score: {}'.format(ars_birch))\n",
    "brc.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True False False False False False False False\n",
      " False False False False False False False False  True False False  True\n",
      " False False  True False False  True False False False  True False False\n",
      "  True False False False False  True False False False  True False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False]\n",
      "[45 28 16 23  1  6 53 49 31 15 51 26 40 32  7 11 54 52 50 22  1  4 47  1\n",
      " 21 24  1  3 42  1 19 35 41  1 36 44  1 38 25 14  2  1 39 10 20  1 55 43\n",
      " 34 13 33 30 17 29  8 12  1  5 18 48 46 37  9 27]\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=0.5,\n",
    "                                 criterion='friedman_mse', min_samples_split=90, min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features='auto', verbose=0,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1,\n",
    "                                 n_iter_no_change=None, tol=0.0001)\n",
    "#clf.fit(x_training, y_training)\n",
    "\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "\n",
    "\n",
    "#train_score = clf.score(x_training, y_training)\n",
    "#test_score = clf.score(x_testing, y_testing)\n",
    "#test_f1 = f1_score(y_testing, clf.predict(x_testing))\n",
    "#print('Train Score:{} Test Score:{}'.format(train_score, test_score))\n",
    "#print('Test F1:{}'.format(test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var6\n",
      "Var22\n",
      "Var25\n",
      "Var28\n",
      "Var31\n",
      "Var35\n",
      "Var38\n",
      "Var43\n",
      "Var47\n",
      "Var58\n"
     ]
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The classifier does not expose \"coef_\" or \"feature_importances_\" attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-7e32ad9c1057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                            p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n\u001b[0;32m      3\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# summarize the selection of the attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda3\\envs\\CS5228\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[0mcoefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'feature_importances_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcoefs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                 raise RuntimeError('The classifier does not expose '\n\u001b[0m\u001b[0;32m    188\u001b[0m                                    \u001b[1;34m'\"coef_\" or \"feature_importances_\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                                    'attributes')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The classifier does not expose \"coef_\" or \"feature_importances_\" attributes"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30,\n",
    "                           p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False  True  True False False False False False False\n",
      "  True False False False False False False False  True False False False\n",
      " False False  True False False False False False False  True False False\n",
      "  True False  True False False False False False  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n",
      "[22 11 17 28  1  1 26 25 14 40 38 24  1 43 16 47 49 48 13 31  1 32 23  3\n",
      "  2  8  1 35 19 18 15 55 54  1 45 44  1 42  1  7 36 12 29 20  1  1 21 39\n",
      " 46  6 41 37 33 27 10 30 34  5  9  4 50 51 52 53]\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(base_estimator=None, n_estimators=65, learning_rate=1, algorithm='SAMME.R', random_state=None)\n",
    "rfe = RFE(clf, 10)\n",
    "rfe = rfe.fit(x_training, y_training)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var6\n",
      "Var7\n",
      "Var14\n",
      "Var22\n",
      "Var28\n",
      "Var35\n",
      "Var38\n",
      "Var40\n",
      "Var46\n",
      "Var47\n"
     ]
    }
   ],
   "source": [
    "useful_features = columns_no_index.copy()\n",
    "for i, feature in enumerate(useful_features):\n",
    "    if rfe.support_[i]:\n",
    "        print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
